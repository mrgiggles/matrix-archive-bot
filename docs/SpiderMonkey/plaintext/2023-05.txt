2023-05-01
[05:29:32.0467] <cassio.neri>
Following a suggestion I'm posting here a question that I've asked in #developers:mozilla.org : I've submitted [D175569](https://phabricator.services.mozilla.com/D175569) two weeks ago. Is there any reason why the review has been delayed?

[05:38:03.0220] <dminor>
cassio.neri: Anba is a volunteer and isn't always able to respond to review requests right away.

[05:40:08.0050] <dminor>
I think Anba is the most qualified reviewer for this, but if you still haven't had a response in another few weeks, I'd be happy to have a look.

[07:45:26.0789] <cassio.neri>
dminor: Thanks for the update. I wrote to Anba last week but, as you said, I think he wasn't able to get online. But that's fine. I can wait a bit longer. 


2023-05-02
[02:02:50.0569] <mayankleoboy1>
Is there a detailed guide for dummies on how to generate more granular js- focussed profiles on Windows?
I have filed a lot of js speed bugs blocking bug 1808325.  I wanted to generate more detailed profiles that will  be more actionable. 

[02:02:52.0488] <botzilla>
https://bugzil.la/1808325 â€” NEW (nobody) â€” [meta] JS Codepen demos that are slower in Firefox than in Chrome

[02:06:45.0215] <mayankleoboy1>
 * Is there a detailed guide for dummies on how to generate more granular js-focussed profiles on Windows? (Similar to the kind that are being filed for SP3 performance)
I have filed a lot of js speed bugs blocking bug 1808325. Instead of the high-level profiles, i want to create the more granular/detailed profiles that are more actionable or more interesting for the devs to fix

[05:10:27.0145] <mstange>
mayankleoboy1: At the moment we can only generate those profiles on Linux. jrmuizel and I are planning to make it work on Windows this week

[08:02:21.0308] <jonco>
How do I make a 32 bit built on 64 bit linux these days?  The documentation says to use |ac_add_options --target=i686| but that isn't working for me

[08:06:28.0728] <jandem>
jonco: `ac_add_options --target=i686-pc-linux` works for me

[08:11:34.0051] <jonco>
jandem: hmm, that also fails. I think my system is broken in some way.

[08:27:38.0243] <jonco>
OK, --enable-clang-plugin was causing problems

[11:38:39.0559] <dug>
 JSAPI JSPropertySpec has a tinyId which looks like an enumeration index. In a getter, (how) can I convert the id to the tiny int / index directly or from its string property name?

[12:07:41.0165] <ptomato>
I would avoid using the tiny ID - I assume you're on a pretty old version of SpiderMonkey? tiny IDs were removed later on, so if you do anything with it now you'll end up having to port your code away from it

[12:10:02.0145] <dug>
> <@pchimento:igalia.com> I would avoid using the tiny ID - I assume you're on a pretty old version of SpiderMonkey? tiny IDs were removed later on, so if you do anything with it now you'll end up having to port your code away from it

yes SM24 upgraded from 1.8.5. In the PropertySpecs we have tinyids defined, so this function in native code works int lookup_tinyid(char* fieldname, JSPropertySpec * properties) {
	JSPropertySpec* p = &properties[0];
	int i = 0;
	int index = -1;
	while(p->name){
		if (!strcmp(p->name, fieldname)) {
			index = p->tinyid;
			break;
		}
		i++;
		p = &properties[i];
	}
	return index;
} and called like this int index = lookup_tinyid(field, ExecutionContextProperties); and then I can share a getter with a switch case on index.

[12:15:24.0111] <dug>
> <@dug:mozilla.org> yes SM24 upgraded from 1.8.5. In the PropertySpecs we have tinyids defined, so this function in native code works int lookup_tinyid(char* fieldname, JSPropertySpec * properties) {
> 	JSPropertySpec* p = &properties[0];
> 	int i = 0;
> 	int index = -1;
> 	while(p->name){
> 		if (!strcmp(p->name, fieldname)) {
> 			index = p->tinyid;
> 			break;
> 		}
> 		i++;
> 		p = &properties[i];
> 	}
> 	return index;
> } and called like this int index = lookup_tinyid(field, ExecutionContextProperties); and then I can share a getter with a switch case on index.

with propertySpec struct looking like this static JSPropertySpec (ExecutionContextProperties)[] = {
	//executionContext
	{"specificationVersion", 0, JSPROP_ENUMERATE},
	{"encoding", 1, JSPROP_ENUMERATE},
	{"profile", 2, JSPROP_ENUMERATE},
	{"components", 3, JSPROP_ENUMERATE},
	{"worldURL", 4, JSPROP_ENUMERATE},
	{"rootNodes", 5, JSPROP_ENUMERATE},
	{"protos", 6, JSPROP_ENUMERATE},
	{"externprotos", 7, JSPROP_ENUMERATE},
	{"routes", 8, JSPROP_ENUMERATE},
	//scene
	//{"specificationVersion", 9, JSPROP_ENUMERATE}, //already done for executionContext above
	{"isScene", 9, JSPROP_ENUMERATE}, //else protoInstance. extra beyond specs - I think flux has it.
	{0,0,0}
};

[12:16:16.0437] <dug>
> <@dug:mozilla.org> with propertySpec struct looking like this static JSPropertySpec (ExecutionContextProperties)[] = {
> 	//executionContext
> 	{"specificationVersion", 0, JSPROP_ENUMERATE},
> 	{"encoding", 1, JSPROP_ENUMERATE},
> 	{"profile", 2, JSPROP_ENUMERATE},
> 	{"components", 3, JSPROP_ENUMERATE},
> 	{"worldURL", 4, JSPROP_ENUMERATE},
> 	{"rootNodes", 5, JSPROP_ENUMERATE},
> 	{"protos", 6, JSPROP_ENUMERATE},
> 	{"externprotos", 7, JSPROP_ENUMERATE},
> 	{"routes", 8, JSPROP_ENUMERATE},
> 	//scene
> 	//{"specificationVersion", 9, JSPROP_ENUMERATE}, //already done for executionContext above
> 	{"isScene", 9, JSPROP_ENUMERATE}, //else protoInstance. extra beyond specs - I think flux has it.
> 	{0,0,0}
> };

Then "rootNodes" is index 5.


2023-05-03
[06:27:25.0339] <smaug>
would it be possible to store "is proxy" flag in the object itself?

[06:27:42.0792] <smaug>
I think the pointer chasing here https://searchfox.org/mozilla-central/rev/e6cb503ac22402421186e7488d4250cc1c5fecab/js/public/Proxy.h#383-384 shows up a bit in the profiles

[07:56:17.0617] <tcampbell>
Unfortunately the only common fields for all JSObjects is the shape pointer, so storing the is-proxy flag would require some reasonably large redesign and rebalance of performance tradeoffs. That being said, JSC does make the tradeoff of using integer IDs instead of pointers for shapes which allows them to pack these sorts of flags. The JIT shape guards remain simple comparisons, but things that need the actual shape data all need to do some pointer math. If we identify a collection of flags beyond just the is-proxy that would have material benefit, then there might be more motivation to redesign this all.

[07:57:38.0786] <tcampbell>
There could be comparatively lighter-weight tricks around laying out virtual address space in clever ways so that even a pointer could give context, but someone would need to understand the fragmentation tradeoffs.

[07:57:59.0643] <jandem>
it used to be `proxy->shape->base->clasp->flags` until pretty recently instead of `proxy->shape->flags` :)

[07:58:19.0841] <jandem>
 * it used to be `object->shape->base->clasp->flags` until pretty recently instead of `object->shape->flags` :)

[08:00:22.0665] <tcampbell>
The other issue with is-proxy flags in profiles is that often that even if you got past that check, there would very likely be a memory stall on the same shape data immediately after. In that case while you might see some speedup for avoiding a load in the memory functional-unit of CPU, the stall time may not be avoided so the wins would be less exciting.

[08:01:10.0717] <tcampbell>
Overall though, evidence of these patterns is good to collect, but I have a hard time believing we would be able to target a single flag in isolation.

[08:02:52.0626] <tcampbell>
(ha.. there we go. Now Jan and Iain can give their own takes.. :)

[08:05:59.0989] <iain>
Yeah, the wins from moving it up from the class to the shape were not as big as we'd hoped, because we often need multiple pieces of information from the class/shape, and unless they've all been hoisted, we end up loading the same memory in the long run

[08:23:18.0147] <Redfire>
I was just testing out my finalise hook and noticed that in a simple script (literally 2 lines), the prototypes always have their finalisers run before the objects themselves. Is this intentional or just coincidental?

[08:23:41.0791] <Redfire>
If it matters, it's background finalisation, not foreground.

[08:28:07.0499] <jandem>
the objects might be in the same arena with the prototype coming first, but that could be different if things were moved, if we filled holes in an arena, if the prototype is being kept alive longer, etc

[08:29:10.0816] <Redfire>
I was thinking given how the prototype chain exists, shouldn't the objects get finalised before the prototypes? Like, technically the object is still using the prototype?

[08:30:38.0434] <iain>
During a garbage collection, we mark all live objects, then sweep up all the dead ones. If the object and the prototype become unreachable in the same collection, then the order in which their finalizers run will just depend on which one the sweep pass happens to see first.

[08:31:52.0905] <Redfire>
So basically it's just a coincidence and the GC is smarter than I thought.

[08:44:04.0848] <mgaudet>
Yeah; this is also why finalizers have to be done with care -- mostly we do a good job hiding too much danger by avoiding providing a JSContext -- as if done incorrectly you can end up with references to dead objects already collected 

[13:38:05.0051] <kfjvj>
Hi there.  I don't know if this issue is know, but I recently encountered undefined behaviour and segfaults when executing a function that took a std::initializer_list<std::tuple<std::string, JS::MutableHandleValue>>

[13:38:18.0054] <kfjvj>
 * Hi there.  I don't know if this issue is a bug or not, but I recently encountered undefined behaviour and segfaults when executing a function that took a std::initializer\_list\<std::tuple\<std::string, JS::MutableHandleValue>>

[13:40:25.0574] <kfjvj>
Should a copy constructor not be used for Mutable handles?

[13:55:09.0811] <kfjvj>
Never mind.  Looks like the issue I was experiencing was due to something else.


2023-05-04
[07:14:56.0544] <davidj361>
How can you check if a `JSContext*` is valid where it's not just a nullptr but not some random memory address?

[07:17:26.0209] <davidj361>
 * How can you check if a `JSContext*` is valid where it's not just a nullptr but also not some random memory address?

[07:17:27.0474] <l11d>
so its neither a nullptr nor a random memory address?

[07:18:04.0698] <davidj361>
yeah, not sure if you can do something akin to isObject() but for JSContext*

[07:18:15.0749] <davidj361>
 * yeah, not sure if you can do something akin to isObject() but for `JSContext*` to see if it's valid

[07:20:34.0782] <l11d>
hmm with `isValue` you check whether a Value is an Object. I'm not sure how this translates to `JSContext`. are you attempting to check whether some kind of C++ object is a `JSContext`?

[07:21:10.0544] <davidj361>
No just seeing if a given JSContext* is a valid JSContext*

[07:21:32.0795] <davidj361>
ah whatever, i guess some random moz assert would pop up

[07:37:11.0598] <Redfire>
Why do you even have `JSContext*` that might not be valid though? ðŸ¤”

[10:01:20.0695] <mgaudet>
"And implements the "RoundDuration" abstract operation. The spec text for
"RoundDuration" is relatively large and we have to implement basically
everything at least two times to have a fast path for the common case and
additionally a slow path which uses BigInts when the numbers can't be stored
in double without loss of precision. Both factors lead to having to write
quite a bit of code for this feature"

On the agenda for this upcoming TC39 meeting is limiting the precision of Temporal... comments like this make me think we ought to support that. 

[10:04:47.0314] <ptomato>
it was actually in the previous TC39 meeting ... my conclusion was that limiting the precision doesn't actually let you avoid BigInt arithmetic, but limiting the range of Temporal.Duration does - so I'm working on an update to Temporal which places an upper bound and should let you get rid of the slow path

[10:06:11.0040] <mgaudet>
Ah ok; that's good. It's awesome that Anba built all the slow / fast path stuff in his stack but it's a lot of code in some places

[10:08:23.0773] <mgaudet>
Actually, if you're around ptomato I have sort of a high level question about duration; has there been conversation that I could read about the fact that comparing durations is linear in the number of years between the two durations? When I was reviewing that patch I thought it was at least a little weird... feels like an awkward denial-of-service vector if someone is processing arbitrary durations and then suddenly processing time jumps hugely because a malicious actor is creating big durations. 

I'm certain this was discussed, but I'd be interested in the discussion

[10:10:24.0665] <ptomato>
there actually hasn't been any discussion specifically about that

[10:10:55.0782] <ptomato>
however, there are more efficient ways possible for builtin calendars where the calendar method calls aren't observable - the loops are needed because of the possibility of custom calendars

[10:11:37.0255] <ptomato>
it's on my todo list to check whether the loops can be eliminated if we do this duration upper bound stuff, though

[10:11:50.0204] <mgaudet>
>  (Playing with the polyfill, comparing a duration of 1y to 1000y takes 24ms; comparing a duration of 1y to 10,000y takes 94ms and 20,000y takes 1970ms. ) 

[10:12:55.0406] <mgaudet>
I haven't tested our implementation to see timing; but the difference of two orders of magnitude of execution time is potentially problematic.

[10:13:49.0870] <mgaudet>
(Not saying this is avoidable in the general case... but maybe it should be a caution for people... documentation?; it's not immediately obvious to someone used to Date being an single number that comparison might be linear time) 

[10:16:01.0480] <mgaudet>
 * I haven't tested our implementation to see timing; but the difference of <del>two</del> three orders of magnitude of execution time is potentially problematic.

[10:21:17.0581] <ptomato>
we do expect that it'll be pretty rare that someone uses a custom calendar

[10:27:01.0624] <mgaudet>
I think this loop also runs every time you use `relativeTo` for compare, which I expect is more normal? 

[10:27:36.0390] <mgaudet>
Or is it more that the loop boils away if you've got the ISO Calendar default (with some analysis) 

[10:28:45.0752] <ptomato>
it boils away if you have any builtin calendar, because they all have some rules about how long years, months, and weeks are - but in the case of a custom calendar you can't assume anything

[10:31:01.0568] <mgaudet>
Ok. Anba's current implementation (spec as of ~march) doesn't do -that- fast path, so I think currently we'll loop even for builtin calendars

[10:32:13.0679] <mgaudet>
(https://phabricator.services.mozilla.com/D174602) 

[10:35:08.0637] <ptomato>
ah, specifically for Duration.compare, there is a PR pending which was approved in TC39 in March which will remove the need for a loop in duration comparison: https://github.com/tc39/proposal-temporal/pull/2519

[10:35:36.0660] <ptomato>
but that loop still exists in the UnbalanceDurationRelative operation, which is used in a couple of other places as well

[10:36:21.0241] <ptomato>
I'm still writing test262 tests for that PR before merging it, but it is technically part of the proposal spec already due to being approved in TC39

[10:43:06.0759] <mgaudet>
Ok, that's definitely good :) I think I was mostly curious about what kind of time-guarantees were acceptable in the proposal methods and what weren't. As I said earlier, it seems surprising for an operation (even if it makes sense in the actual depth of understanding) for an operation to have a complexity related to the number of years for example. So one can imagine it being a vector of abuse, which consumers of the library now need to prepare for.

I was looking for discussion mostly to try to understand some of the philosophy behind the approach to this

[10:46:53.0072] <ptomato>
I agree, ... any relevant discussion probably centers around the existence of custom calendars though, and not specifically this

[10:47:38.0088] <mgaudet>
ptomato: is this something which ought to be tossed onto an issues queue or agenda somewhere? Or probably too late?

[10:48:59.0839] <ptomato>
I'll put it on the agenda for the next Temporal champions meeting in any case

[10:49:28.0734] <ptomato>
(which you're welcome to drop in on if you like!)

[10:49:30.0470] <ptomato>
I hope the stuff I'm working on will obsolete it, though

[10:49:40.0618] <mgaudet>
ðŸ¤ž

[16:27:33.0452] <Redfire>
Is there any equivalent to `ForOfIterator` for async iterators (ie `Symbol.asyncIterator`?

[16:27:41.0213] <Redfire>
* Is there any equivalent to `ForOfIterator` for async iterators (ie `Symbol.asyncIterator`)?


2023-05-05
[03:41:52.0699] <smaug>
jandem: jonco curious, has anyone looked into https://bugzilla.mozilla.org/show_bug.cgi?id=1821293 yet?

[03:42:29.0122] <smaug>
Does js engine perhaps need some more information whether DOM thinks the global is probably gone

[03:43:57.0042] <jonco>
smaug: I guess this is on my backlog but I don't have time to work on it at the moment

[03:46:43.0722] <smaug>
ok. Looks like especially Android and linux would like using less memory while running sp3.  Perhaps I'll try to hack something there

[04:17:29.0771] <Redfire>
Will the mastodon account be moving over to mozilla.social? ie this one https://mastodon.social/@SpiderMonkey

[04:57:26.0255] <nbp>
is that even possible to have a Firefox account held by a group of persons instead of invididuals?

[04:58:00.0126] <nbp>
Let's not ask why this service even requires a Firefox Account ðŸ¤¦

[05:55:46.0887] <jonco>
evilpie: hey, I'm looking at WPT failures related to worker modules.  I saw you filed for the credentials failures.  Do you happen to know why the following tests are failing? /workers/modules/dedicated-worker-import-data-url-cross-origin.html and /workers/modules/dedicated-worker-import-referrer.html (plus shared- versions)

[06:13:01.0422] <mgaudet>
> <@nbp:mozilla.org> is that even possible to have a Firefox account held by a group of persons instead of invididuals?

Apparently it's planned

[06:16:16.0487] <evilpie>
> <@jonco:mozilla.org> evilpie: hey, I'm looking at WPT failures related to worker modules.  I saw you filed for the credentials failures.  Do you happen to know why the following tests are failing? /workers/modules/dedicated-worker-import-data-url-cross-origin.html and /workers/modules/dedicated-worker-import-referrer.html (plus shared- versions)

Let me take a look. Most likely it's the same root cause that is also causing problems for CSP.

[06:32:53.0664] <evilpie>
For `dedicated-worker-import-data-url-cross-origin.html` I am not really sure what is going on. I wasn't aware of this restriction for imports from data: URLs. I suspect we might be missing something from fetch, but I would necessarily trust the WPT 100% either.

[06:57:15.0198] <Jared Hirsch [:jhirsch]>
hey folks - what are the suggested mozconfig settings for spidermonkey? I'm guessing a debug build with sccache enabled, curious if I'd want to disable-optimize or make additional tweaks to ease debugging

[06:59:54.0249] <evilpie>
jonco: for the dynamic import issue. We seem to always be using the fetchOptions (which contains the referrer policy) from the active script (which I think would be the main Worker script fetched with the windows' policy) in `WorkerModuleLoader::CreateDynamicImport`. I think `workerPrivate->GetReferrerPolicy()` set from `WorkerPrivate::UpdateReferrerInfoFromHeader` would be correct instead

[07:00:28.0520] <jonco>
evilpie: great, thank you for investigating these

[07:46:53.0069] <Jared Hirsch [:jhirsch]>
 * [edit: found the answer in [the docs](https://firefox-source-docs.mozilla.org/js/build.html#setting-up-a-mozconfig), sorry!] hey folks - what are the suggested mozconfig settings for spidermonkey?

[15:07:35.0856] <rice7th>
Hello! Sorry for the newly created account.

[15:08:54.0193] <rice7th>
I've recently made a post on r/firefox about the concerning performance of Spidermonkey compared to V8 and JSC. https://www.reddit.com/r/firefox/comments/138uciq/why_spidermonkey_is_way_slower_than_v8_or/

[15:09:13.0710] <rice7th>
somebpdy in the comments told me to ask here for more technical details, so here am I.

[15:10:06.0616] <rice7th>
I need to however warn you that I am still learning such topics and I might have said some wrong things, so please, correct me if I am wrong

[15:15:44.0518] <mccr8>
SpiderMonkey hasn't been a tracing JIT for around a decade, for what it is worth.

[15:17:22.0947] <mccr8>
Also, Octane 2.0 is about a decade old. I wouldn't worry too much about how different engines perform in that.

[15:18:02.0615] <mccr8>
If you have specific websites where Firefox is slow, you are better off filing issues for those and not focusing on benchmarks. Writing a good benchmark is very difficult, so looking at actual website performance is a better place to start.

[15:20:33.0823] <iain>
rice7th: Octane is basically retired at this point. V8 wrote a good blog post about why: https://v8.dev/blog/retiring-octane

[15:23:19.0786] <iain>
When we did a big overhaul of our optimizing compiler a few years ago (https://hacks.mozilla.org/2020/11/warp-improved-js-performance-in-firefox-83/), we made the deliberate choice not to worry about getting Octane performance back, because it mostly doesn't matter in the real world

[15:26:04.0746] <iain>
The benchmark of choice these days is Speedometer. We're still a bit behind Chrome on it, but we're in the middle of an active push to catch up. Speedometer 3 (an updated version of the current Speedometer 2) is currently being developed as a collaboration between the major browsers; we are aiming for at least parity when it releases.

[15:29:36.0569] <iain>
The goal of any good benchmark is to capture similar behaviour to real-world websites, so that improving the benchmark score makes performance better for real users. If you have real-world use cases where Firefox is noticeably slower, please open a bug. The more specific you can be, the better.


2023-05-06
[23:12:43.0015] <liam_g>
What are use cases for `JSPropertySpec`? Looking at the code in PropertySpec.h, I can pretty much work out what it does (i.e. it's used for defining properties in native classes). I want to know why / when this would be preferable to just defining properties using `JS_DefineProperty()`. Specifically, I'm wondering whether it's faster than using `JS_DefineProperty()`.

[23:18:30.0584] <liam_g>
 * What are use cases for `JSPropertySpec`? Looking at the code in PropertySpec.h, I can pretty much work out what it does (i.e. it's used for defining properties in native classes). I want to know why / when this would be preferable to just defining properties using `JS_SetProperty()`. Specifically, I'm wondering whether it's faster than using `JS_SetProperty()`.

[00:59:49.0390] <cassio.neri>
I hope [D175569](https://phabricator.services.mozilla.com/D175569) can help improving Firefox performance. I'd happy to assist and explain the patch/algorithm if needed but bear in mind that I'll be off this week in a C++ conference (presenting this very same algorithm).

[04:23:26.0275] <rice7th>
> <@mccr8:mozilla.org> SpiderMonkey hasn't been a tracing JIT for around a decade, for what it is worth.

oh, so is it method jit now?

[04:24:31.0451] <rice7th>
> <@iain:mozilla.org> The goal of any good benchmark is to capture similar behaviour to real-world websites, so that improving the benchmark score makes performance better for real users. If you have real-world use cases where Firefox is noticeably slower, please open a bug. The more specific you can be, the better.

Mainly Reddit (somehow) and any other either JavaScirpt heavy or webgl heavy applications such as Photopea or Figma

[05:10:16.0431] <mbroadst>
Good morning, does SpiderMonkey have a concept similar to v8's [startup snapshots](https://github.com/danbev/learning-v8/blob/master/notes/snapshots.md)? I'm sure I'm just not imagining the right search terms. 

[05:19:21.0191] <mbroadst>
ptomato: maybe more specifically to your case, have you considered using something like startup snapshots (if they exist for SpiderMonkey) to improve load time of gjs? 

[10:12:54.0074] <ptomato>
Startup time doesn't really bottleneck anything for gjs, so it's not been on my radar


2023-05-07
[03:49:15.0699] <mbroadst>
I see, thanks. I have an embedding which needs to load a lot of javascript files each times it starts up, it takes ~400ms in by my measurement. It would be great if I could snapshot that to avoid the same initial load time each time the binary is executed. 


2023-05-08
[01:27:02.0172] <liam_g>
I'm using JS::Evaluate to evaluate some code. It's something very simple like this pseudo-code:
`````
JS::RootedObject global (cx, createGlobal(cx));
JS::Evaluate(cx, "var a = 1; let b = 2");
js::DumpObject(global);
`````
When I do this, the global object shows variable a, but not variable b. This makes sense, given that b is locally scoped. My question is, where is b stored in the system? And can I access b using Spidermonkey code, even though it is locally scoped?

[01:29:22.0757] <liam_g>
My real situation is a bit more complicated, using an object being sent in through the env-chain rather than the global object, but I think it boils down to the same thing. I'm asking because the local let variable still seems to be accessible in the script, even though it "isn't there".

[01:30:41.0249] <arai>
I thought you were looking into `JS_GlobalLexicalEnvironment` and `JS_ExtensibleLexicalEnvironment`, right?

[01:30:45.0892] <arai>
don't they work?

[01:46:43.0999] <liam_g>
That part worked really nicely. This is something else.

[01:47:17.0026] <liam_g>
Unless you mean that I can find a variable created with "let" in the global lexical environment?

[01:48:23.0700] <arai>
it should be stored in the lexical environment object

[01:48:45.0993] <arai>
either in the global or the extensible one, depending on the context

[01:50:16.0240] <liam_g>
Yes, it's there!

[01:50:33.0272] <liam_g>
That's awesome, I thought this was going to be really difficult. Thanks @arai.

[05:42:45.0798] <sdetar>
*

[06:08:25.0152] <whimboo>
Hi. does anyone have an advice how I could return a Promise from within an async method? awaiting for the result of the method should actually not wait for the "inner" promise to be resolved

[06:09:00.0944] <whimboo>
I would like to avoid having to wrap the promise like `return {inner: promise}`

[06:23:08.0999] <arai>
I don't think there's simple way.  why do you want to keep the inner promise unresolved?  is there any difference you observe with it?

[06:26:11.0819] <whimboo>
arai: for webfdriver bidi we create strong handles for clients that they can refer to at a later time. As such it is possible to resolve the promise a couple of steps later within a eg. script execution step

[06:26:29.0786] <whimboo>
but the deserialization step should not be blocked by it

[06:27:35.0601] <whimboo>
so I'll go ahead with the wrapper then

[06:32:55.0572] <arai>
yeah, wrapping it with an object or array would be the best way.  other option I can think of is to use out parameter for the inner promise, but it's almost same complexity

[06:34:24.0923] <whimboo>
hm what is this out parameter exactly?

[07:48:17.0028] <arai>
something like this:
```js
async function f(out) {
  out.value = promise;
  return true;
}

let out = { value: null };
await f(out);
let promise = out.value;
```


[08:32:04.0598] <mgaudet>
"Your flight has changed" says the email, with no diff on what happened. Turns out, one of my flights scheduled arrival times changed by two minutes. ðŸ¤¦

[08:39:46.0775] <Ms2ger>
For the better?

[08:44:32.0158] <sfink>
My wife went to New Zealand last November, and received exactly that notificationâ€”except the change was for two *days*. Two days earlier, to be precise. It was... exciting.

[09:09:51.0186] <mgaudet>
O.o 

[09:10:11.0124] <mgaudet>
See... this is why I had to hand diff the email (and why I was irked it didn't include a diff) 

[09:10:43.0035] <mgaudet>
> <@ms2ger:igalia.com> For the better?

The flight is 2 minutes longer... so worse? but like... not very much worse.

[12:43:19.0022] <mgaudet>
Tenured objects donâ€™t move right?

[12:50:18.0814] <iain>
mgaudet: They can during a compacting GC

[12:50:43.0418] <mgaudet>
ah, ok. that's good to know :) 

[12:51:06.0067] <iain>
Note that we throw away Ion code for compacting GCs, so we can cheat and pretend they don't move for the purposes of Ion

[12:51:25.0052] <iain>
(But we still have to handle nursery objects)

[12:51:49.0161] <mgaudet>
ok, that makes sense. 

[13:48:37.0510] <aswan>
Hi, not sure if this is an appropriate place for this question, but I'm wondering about how to preload js modules?  I see there's a a `<link rel="modulepreload" ...>` but that it is not supported by firefox (or safari).  In these browsers (or at least in ff) is `<link rel="preload" as="script" ...>` effective for preloading a module?

[13:53:33.0770] <mccr8>
It looks like it is being worked on... https://bugzilla.mozilla.org/show_bug.cgi?id=1425310

[13:58:07.0567] <zcorpan>
aswan: also see https://developer.chrome.com/blog/modulepreload/#ok-so-why-doesnt-link-relpreload-work-for-modules

[14:01:04.0378] <aswan>
ooh, thank you for that link!  do i understand correctly that until modulepreload is supported, it's not possible to preload modules?

[14:03:38.0849] <zcorpan>
I think you can use `<link rel=preload as=script crossorigin href=foo><script type=module crossorigin src=foo>` and that should put it in cache and there should be a cache hit, but it won't fetch dependencies or parse the script

[14:05:14.0961] <aswan>
cool.  and practically, that probably means sniffing the user agent to decide which tag to use for now?

[14:07:29.0404] <zcorpan>
Demo: https://software.hixie.ch/utilities/js/live-dom-viewer/saved/11639 - checking devtools network panel in Firefox the second fetch sasy "cached" (after I disable "disable cache"!)

[14:08:16.0540] <zcorpan>
I *guess* preloading other scripts in the module graph should also work, but haven't tested

[14:13:34.0011] <zcorpan>
UA sniffing doesn't seem great. I was going to suggest `rel="preload modulepreload"` could work but it seems to not preload anything in safari

[14:15:30.0677] <zcorpan>
But including both `<link rel="modulepreload">` and `<link rel="preload">` doesn't seem to double-fetch

[14:25:05.0489] <TheQwertiest>
hey everyone!
is it possible to somehow nuke object from native side, so that it would be inaccessible in js side? (e.g. throw js error when trying to access it)
object itself is created in native side.

[14:26:07.0212] <aswan>
thank you zcorpan this has all been very helpful!

[14:26:47.0900] <mccr8>
> <@theqwertiest:mozilla.org> hey everyone!
> is it possible to somehow nuke object from native side, so that it would be inaccessible in js side? (e.g. throw js error when trying to access it)
> object itself is created in native side.

Sort of. There is a way to do that for cross compartment wrappers.

[14:27:18.0284] <mccr8>
See js::NukeCrossCompartmentWrappers() and the like.

[14:27:29.0964] <TheQwertiest>
> <@mccr8:mozilla.org> Sort of. There is a way to do that for cross compartment wrappers.

yea, I remember doing that for my cross-world needs =)
but this time it's on the same realm

[14:27:41.0567] <TheQwertiest>
> <@mccr8:mozilla.org> Sort of. There is a way to do that for cross compartment wrappers.

 * yea, I remember doing that for my cross-world needs =)
but this time it's on the same realm, so there are no wrappers to nuke

[14:27:58.0027] <mgaudet>
TheQwertiest: Cross Compartment Wrappers are special proxies where the target can be removd; you could restructure things sucht that your native code only ever exposes a proxy, then 'nuke' by affecting the proxy

[14:28:19.0747] <mccr8>
Technically you probably could using brain transplants, but it is rather nasty stuff. We swap CCWs and tese cross process object things.

[14:28:29.0741] <mccr8>
 * Technically you probably could using brain transplants, but it is rather nasty stuff. We swap CCWs and these cross process object things.

[14:29:01.0837] <mgaudet>
(Another topic:) So I've been doing some digging into environment objects. I'm drawing a blank at the moment; maybe someone can help me clear it up (alas, going to post this then go AFK for a bit). Suppose you have some environment chain starting at object A, and you access a variable at A+2 hops. 

Is it possible that the environment A + 2 hops can ever be a different object? (I have some empirical evidence that says yes, but I don't quite understand yet -- I will eventually toss this in a debugger, but maybe there's a simple explanation) 

[14:29:07.0510] <mgaudet>
Somethingthing something `with`?

[14:29:28.0011] <TheQwertiest>
> <@mgaudet:mozilla.org> TheQwertiest: Cross Compartment Wrappers are special proxies where the target can be removd; you could restructure things sucht that your native code only ever exposes a proxy, then 'nuke' by affecting the proxy

well, I don't want to nuke every proxy, I need to nuke a single object =)

[14:30:15.0405] <mgaudet>
Right -- but you wrap that object in a proxy, then every handler checks if the permission is denied before doing anything

[14:30:42.0935] <mgaudet>
and you only expose to the JS the -proxy- to that object, never the native. Then JS can be denied access always by flipping the switch on the proxy

[14:31:34.0027] <mccr8>
The general way to do this is allocate a new object of the same class, then do JSObject::swap() on it. But this is some of the nastiest code we have so things can go horribly wrong...

[14:31:37.0218] <TheQwertiest>
> <@mgaudet:mozilla.org> Right -- but you wrap that object in a proxy, then every handler checks if the permission is denied before doing anything

oh, do you mean manually creating a proxy? (i.e. not through WrapValue)

[14:31:54.0005] <mgaudet>
> <@theqwertiest:mozilla.org> oh, do you mean manually creating a proxy? (i.e. not through WrapValue)

Yes. 

[14:31:55.0586] <TheQwertiest>
> <@mgaudet:mozilla.org> Right -- but you wrap that object in a proxy, then every handler checks if the permission is denied before doing anything

 * oh, do you mean manually creating a proxy? (i.e. not craeting a wrapper through WrapValue)

[14:32:36.0387] <mccr8>
I guess JS_TransplantObject is a slightly higher level interface to it. But yeah look at this comment... https://searchfox.org/mozilla-central/rev/4e6970cd336f1b642c0be6c9b697b4db5f7b6aeb/js/src/jsapi.cpp#587

[14:33:01.0812] <mccr8>
I think you'd be implementing your own similar thing using swap.

[14:33:20.0552] <TheQwertiest>
"Not for beginners or the squeamish." well that sounds rather nice :D

[14:33:40.0156] <mccr8>
I implemented a new use of swapping for Fission stuff and it took like a month or two.

[14:33:59.0617] <mccr8>
That was in here. https://bugzilla.mozilla.org/show_bug.cgi?id=1510760

[14:34:00.0195] <TheQwertiest>
> <@mgaudet:mozilla.org> Yes.

hm... this might work, though I'm not sure if the work required is worth it.
but thanks anyway =)

[14:34:36.0265] <TheQwertiest>
(since there is only one object in one scenario that requires it...)

[14:34:45.0503] <TheQwertiest>
 * (since there is only one object in a single scenario that requires it...)

[14:34:47.0200] <mccr8>
(also new regressions kept popping up for like a year)


2023-05-09
[05:55:07.0316] <nbp>
sfink: Haven't you already reported the self-test failure previously?

[06:54:38.0451] <tcampbell>
The more practical way to destroy JSObjects from your C++ code is to just add checks to the start of each accessor that throw if the underlying resource you are worried about is gone. We use this for things like the Debugger API (which is JSObjects in one realm abstracting over stuff in another realm). Also, ArrayBuffers effectively do this since the system can put them into "detached" state.

[07:40:12.0397] <sfink>
nbp: uh... did I? It sounds like something I might do.

[07:41:18.0097] <sfink>
(even though I'm in Paris, I guess I'm still not exactly keeping local time. Just got back from renting a [musical] keyboard.)

[07:43:01.0799] <Ms2ger>
/me passes sfink a baguette and a beret

[12:54:11.0516] <mgaudet>
iain: When it comes to GC do cacheIR stubs hold all objects they reference alive, or only a subset (I know there was talk about putting weak pointers into CacheIR, but I can't recall if it was for every GC pointer or just a subset of them

[12:54:52.0438] <iain>
They're all strong pointers

[12:55:20.0905] <iain>
There has been talk about weak pointers, but only talk

[12:55:50.0160] <mgaudet>
Awesome. Thanks :) 

[12:57:12.0078] <iain>
We do throw away some stubs on GC, but only if the stub can't do a call that could trigger a GC, because we don't want to throw away a stub that is currently on the stack

[12:57:37.0272] <mgaudet>
Ok. That's good to know as well.

[12:57:50.0823] <mgaudet>
(How are those stubs chosen? Only on Shrinking GCs right?) 

[12:59:23.0293] <iain>
https://searchfox.org/mozilla-central/source/js/src/jit/BaselineCacheIRCompiler.cpp#101

[13:00:21.0010] <iain>
We allocate stubs in two different spaces, depending on whether they ever enter a stub frame (which is a prerequisite for doing a VM call)

[13:16:24.0363] <mgaudet>
iain: Another quick Q: Your baseline batching code is just helps with baseline right? CacheIR will need a separate answer right? 

[13:24:38.0334] <iain>
mgaudet: It will need a separate answer, but at least in theory some of the infrastructure I'm building to enable us to generate multiple instances of JitCode within a single mprotect can be reused for batching baseline ICs.

[14:05:47.0153] <jrmuizel>
iain: what is DoCallFallback about? Why do we need to ever go into C++ when calling baseline code from baseline?

[14:05:53.0618] <mstange>
example: https://share.firefox.dev/3LMNFw5

[14:06:28.0512] <mstange>
ah, this was probably an old eager-baseline run

[14:06:57.0043] <iain>
jrmuizel: That's the fallback for the call IC. It's equivalent to IonCallIC::update (except we don't use call ICs in Ion)

[14:07:54.0445] <iain>
The first time we do a call at a given point, we call into C++ to check what kind of call it is, including checking to see if it's a builtin that gets special handling 

[14:08:41.0275] <iain>
And then we attach an IC, and then we do the actual call (from C++, because we're already there)

[14:09:37.0193] <jrmuizel>
What kind of calls are there?

[14:09:47.0806] <jrmuizel>
* What kinds of calls are there?

[14:13:48.0808] <iain>
Calls to other jit code, calls to C++ builtins, calls to bound functions, classes with a [call hook](https://searchfox.org/mozilla-central/source/js/public/Class.h#602), calls to builtins that get turned into bespoke CacheIR instead of an actual call

[14:14:08.0580] <iain>
Most of which can also be a constructor call and/or a spread call

[14:14:54.0909] <iain>
jrmuizel: Security people are asking what the performance delta of mprotect is. What is our current number?

[14:15:49.0911] <iain>
(Oh, also there's special optimization for function.call and function.apply to try skipping the builtin and calling the target directly)


2023-05-10
[04:48:50.0615] <sfink>
jonco: warning - from the looks of bug 1832284, it appears I broke the check for detecting whether any hazards were reported. I should probably be basing it off of the json now, but at the moment it looks like it's attempting to figure it out from a nonexistent file.

[04:48:52.0977] <botzilla>
https://bugzil.la/1832284 â€” NEW (jonco) â€” Permanent failure line for successful hazard tasks: hazards | unrooted 'na' of type 'js::NativeObject*' live across GC call at js/src/vm/JSObject.cpp:1380 - DO NUT USE FOR CLASSIFICATION

[04:49:57.0418] <sfink>
ah, I renamed rootingHazards.txt â†’ hazards.txt. Oopsie.

[04:50:36.0830] <jonco>
hah, I was wondering how I managed to sneak a hazard past CI

[04:51:33.0825] <sfink>
ugh, in the JSON it would require finding two lines, so it's not just a simple grep. I'll just switch over to the new name for now.

[04:53:50.0740] <sfink>
heh, and I *did* change the name for the part that produces the TinderboxPrint: message, which at one point was enough to make the job fail.

[04:56:18.0479] <sfink>
I uploaded my fix to the bug, but I'm headed out for lunch now. I guess it'll have to land together with your fix, so feel free to push it whenever convenient.

[04:57:11.0746] <sfink>
it's kinda nice being in almost the same time zone

[06:59:56.0592] <jonco>
sfink: I guess I should have held off landing your patch

[07:00:18.0861] <sfink>
oh, whoops. I'll make a followup patch instead.

[07:04:01.0092] <sfink>
(the remaining references are harmless, though I have a try push going to make sure)

[08:51:22.0949] <jonco>
sfink: ping

[08:54:50.0484] <sfink>
Back in 20min

[08:55:56.0143] <jonco>
sfink: it's meeting time now, but maybe we can skip this week (or do it daytime tomorrow)

[09:17:14.0919] <sfink>
oh! Shoot, I keep missing things because I forget they're going to be at a totally different time of day.

[09:19:46.0082] <sfink>
I guess I don't have a lot to talk about. I've mostly just been working on a small change to structured clone, and a resulting larger piece of testing infrastructure, and a fuzzy set of followup fixes now that I'm reading the latest spec and looking at the state of the code.

[09:23:31.0546] <jonco>
great

[09:23:44.0398] <jonco>
I'm still working on WeakMap.get optimisations and have landed most of the patches I talked about last week.
I'm planning on continuing with that and then looking at nursery allocation optimisation in the interpreter.

[09:31:17.0124] <barret>
Hi y'all. I've got a stack that doesnt make any sense:

```
[task 2023-05-09T16:01:17.057Z] 16:01:17     INFO - PID 8712 | WARNING: Error: Phase "profile-before-change" is finished, it is too late to register completion condition "OS.File: flush I/O queued before profileBeforeChange"
[task 2023-05-09T16:01:17.057Z] 16:01:17     INFO - PID 8712 | WARNING: addBlocker@resource://gre/modules/AsyncShutdown.sys.mjs:727:15
[task 2023-05-09T16:01:17.058Z] 16:01:17     INFO - PID 8712 | addBlocker@resource://gre/modules/AsyncShutdown.sys.mjs:523:26
[task 2023-05-09T16:01:17.058Z] 16:01:17     INFO - PID 8712 | addBlocker@resource://gre/modules/AsyncShutdown.sys.mjs:458:15
[task 2023-05-09T16:01:17.059Z] 16:01:17     INFO - PID 8712 | setupShutdown@resource://gre/modules/osfile/osfile_async_front.jsm:1548:28
[task 2023-05-09T16:01:17.059Z] 16:01:17     INFO - PID 8712 | @resource://gre/modules/osfile/osfile_async_front.jsm:1568:16
[task 2023-05-09T16:01:17.060Z] 16:01:17     INFO - PID 8712 | @resource://gre/modules/osfile.jsm:12:30
[task 2023-05-09T16:01:17.062Z] 16:01:17     INFO - PID 8712 | @resource://gre/modules/TelemetryStorage.sys.mjs:10:28
[task 2023-05-09T16:01:17.062Z] 16:01:17     INFO - PID 8712 | _checkPendingPings@resource://gre/modules/TelemetrySend.sys.mjs:863:17
```

TelemetrySend.sys.mjs:863 is `return`
TelemetryStorage.sys.mjs:80 is imports `Preferences.sys.mjs`
There should be no outstanding imports of osfile.jsm anywhere in non-test files at this point

[09:31:41.0745] <barret>
From this log https://treeherder.mozilla.org/logviewer?job_id=415084712&repo=mozilla-central&lineNumber=26025

[09:53:27.0818] <barret>
TelemetryStorage.sys.mjs:10 *used* to import osfile.jsm https://hg.mozilla.org/mozilla-central/file/e221ddc823c0e35cf78f0a15f9ecec8bae088da2/toolkit/components/telemetry/app/TelemetryStorage.sys.mjs#l10

[09:53:36.0113] <barret>
 * Hi y'all. I've got a stack that doesnt make any sense:

```
[task 2023-05-09T16:01:17.057Z] 16:01:17     INFO - PID 8712 | WARNING: Error: Phase "profile-before-change" is finished, it is too late to register completion condition "OS.File: flush I/O queued before profileBeforeChange"
[task 2023-05-09T16:01:17.057Z] 16:01:17     INFO - PID 8712 | WARNING: addBlocker@resource://gre/modules/AsyncShutdown.sys.mjs:727:15
[task 2023-05-09T16:01:17.058Z] 16:01:17     INFO - PID 8712 | addBlocker@resource://gre/modules/AsyncShutdown.sys.mjs:523:26
[task 2023-05-09T16:01:17.058Z] 16:01:17     INFO - PID 8712 | addBlocker@resource://gre/modules/AsyncShutdown.sys.mjs:458:15
[task 2023-05-09T16:01:17.059Z] 16:01:17     INFO - PID 8712 | setupShutdown@resource://gre/modules/osfile/osfile_async_front.jsm:1548:28
[task 2023-05-09T16:01:17.059Z] 16:01:17     INFO - PID 8712 | @resource://gre/modules/osfile/osfile_async_front.jsm:1568:16
[task 2023-05-09T16:01:17.060Z] 16:01:17     INFO - PID 8712 | @resource://gre/modules/osfile.jsm:12:30
[task 2023-05-09T16:01:17.062Z] 16:01:17     INFO - PID 8712 | @resource://gre/modules/TelemetryStorage.sys.mjs:10:28
[task 2023-05-09T16:01:17.062Z] 16:01:17     INFO - PID 8712 | _checkPendingPings@resource://gre/modules/TelemetrySend.sys.mjs:863:17
```

TelemetrySend.sys.mjs:863 is `return`
TelemetryStorage.sys.mjs:10 is imports `Preferences.sys.mjs`
There should be no outstanding imports of osfile.jsm anywhere in non-test files at this point

[10:54:12.0264] <nika>
cc jonco - as this might be related to module loader stuff in some way?

[10:54:37.0822] <nika>
Also kmag in case this is related to startup cache somehow (though how would the worker have a busted startup cache?)

[10:58:24.0532] <kmag>
Yeah, I don't think WPT should ever use a profile from previous pushes...

[10:59:36.0579] <kmag>
Could always try a push where you force disable the startup cache and script preloader, or purge them at startup and see if it goes away

[14:07:46.0650] <arai>
`TelemetrySend.sys.mjs:863:17` matches to `await lazy.TelemetryStorage` in https://hg.mozilla.org/mozilla-central/annotate/30ed0e6529a5d4d49f0b63014947f655e257135f/toolkit/components/telemetry/app/TelemetrySend.sys.mjs#l863 (from 30 Mar 2023).  so, it's likely that there's some cache issue


2023-05-11
[08:14:15.0587] <Bryan Thrall [:bthrall]>
I'm experimenting with keeping the JSScript stored in `BaselineFrame::interpreterScript_` after Baseline Compile, but the GC is complaining when I trace that field points to the Nursery even though it is a TenuredCell. The GC is happy tracing the field when in the Baseline Interpreter.
The backtrace is: 
```#0  js::gc::IsInsideNursery(js::gc::TenuredCell const*) (cell=<optimized out>)
    at /home/bryan/src/mozilla-unified/obj-debug-x86_64-pc-linux-gnu/dist/include/js/HeapAPI.h:606
#1  js::CheckTracedThing<js::BaseScript>(JSTracer*, js::BaseScript*)
    (trc=trc@entry=0x7fffffffc1e0, thing=0x7ffff762e100)
    at /home/bryan/src/mozilla-unified/js/src/gc/Marking.cpp:142
```
I do think I need to trace the field when the frame is for Baseline Compiled code, but I'm not sure how to debug this.

[08:16:34.0759] <Bryan Thrall [:bthrall]>
 * I'm experimenting with keeping the JSScript stored in `BaselineFrame::interpreterScript_` after Baseline Compile, but the GC is complaining when I trace that field points to the Nursery even though it is a TenuredCell. The GC is happy tracing the field when in the Baseline Interpreter.
The backtrace is:

```
#0  js::gc::IsInsideNursery(js::gc::TenuredCell const*) (cell=<optimized out>)
    at /home/bryan/src/mozilla-unified/obj-debug-x86_64-pc-linux-gnu/dist/include/js/HeapAPI.h:606
#1  js::CheckTracedThing<js::BaseScript>(JSTracer*, js::BaseScript*)
    (trc=trc@entry=0x7fffffffc1e0, thing=0x7ffff762e100)
    at /home/bryan/src/mozilla-unified/js/src/gc/Marking.cpp:142
```

I do think I need to trace the field when the frame is for Baseline Compiled code, but I'm not sure how to debug this.

[08:18:36.0962] <jandem>
Bryan Thrall [:bthrall]: the field probably contains a garbage value. Maybe you can get the script from the callee token and use that to decide whether you have a valid interpreterScript you have to trace 

[08:19:00.0572] <iain>
Bryan Thrall [:bthrall]: Does removing this check help? https://searchfox.org/mozilla-central/source/js/src/jit/BaselineFrame.cpp#55-57

[08:19:30.0589] <iain>
Or rather, replacing it with an is-self-hosted check?

[08:23:56.0166] <Bryan Thrall [:bthrall]>
Yes, the problem is when I perform the `Trace()` call on BaselineFrame.cpp:56 when `!runningInInterpreter()`.
I have a bit of plumbing to do before I can replace it with a `isSelfHosted()` check, but that seems like a good thing to try

[08:30:35.0205] <Bryan Thrall [:bthrall]>
I think you're right, jandem ; I'm only storing the script pointer for functions right now, so I imagine tracing that value for non-function frames (I think those can happen, right?) would have a garbage value

[08:31:43.0236] <iain>
Top-level scripts, eval scripts, and module scripts are not functions


2023-05-12
[03:41:11.0276] <sfink>
dates and times are complicated

[03:41:15.0971] <sfink>
humans suck

[03:42:25.0462] <sfink>
(head explosion number N, where N is large, while reviewing https://web.archive.org/web/20230316163651/https://tc39.es/proposal-temporal#sec-temporal-disambiguatepossibleinstants )

[04:51:12.0584] <sfink>
\o/ I just marked my last Temporal review in the spreadsheet, I think it's officially back over to anba now!

[05:26:59.0109] <nbp>
We should reject any backward compatibility of dates and adopt stardate.

[05:58:30.0211] <sfink>
I'm just worried about what will happen when someone needs to incorporate relativistic travel. "You want to know nanoseconds since the epoch? Sure, just pass in your complete history of acceleration. Oh, and you started on Earth, right?"

[06:00:13.0039] <sfink>
> <@sfink:mozilla.org> \o/ I just marked my last Temporal review in the spreadsheet, I think it's officially back over to anba now!

To be clear: I was the laggard, everyone else finished theirs earlier.

[06:04:35.0585] <nbp>
Well â€¦ given the size of the earth ( 6.3781Â·10â¶ m ) and the speed of light ( 299792458 m/s ). One light pulse takes more than 21ms to go from one side to the other.
Thus if you want to consider relativistic effect, you can already do so.

[06:06:32.0869] <nbp>
Then, if you are in a space station orbiting the earth, then we can consider other relativistic effects â€¦

[06:08:01.0868] <Ms2ger>
Mars time is a V2 feature


2023-05-15
[05:24:18.0950] <Redfire>
If two objects each store a `Heap<JSObject*>` with the other object and trace it in their trace hooks, does that cause a memory leak or something?

[05:24:48.0741] <Redfire>
Particularly I'm implementing URLSearchParams currently

[05:25:15.0308] <Redfire>
* Particularly I'm implementing URLSearchParams currently, in which URL needs to store the former and the former needs to store URL to access it

[05:51:41.0916] <evilpie>
They will be gced if they are unreachable from anywhere else

[06:13:18.0939] <Redfire>
Yet again the GC is smarter than I gave it credit.

[06:13:36.0419] <Redfire>
Didn't realise it accounted for cylic dependencies 

[07:50:02.0467] <mccr8>
It won't work if the cycle goes through C++, but a pure JS cycle should be fine. (In Firefox, we have a separate GC-ish thing called the cycle collector to deal with cycles through C++ and JS.)

[08:10:01.0685] <Redfire>
uhh it goes through C++, both in private values in reserved slots and traced with trace hooks

[08:28:55.0239] <mccr8>
> <@redfire75369:mozilla.org> uhh it goes through C++, both in private values in reserved slots and traced with trace hooks

Ah. If you are implementing this in Firefox, you'll need to make your C++ classes participate in cycle collection. https://firefox-source-docs.mozilla.org/xpcom/cc-macros.html

[09:01:28.0745] <Redfire>
Not in Firefox, and its in rust too so technically doesn't apply ðŸ˜­

[09:02:03.0869] <Redfire>
What's the solution then?

[09:06:52.0527] <mccr8>
> <@redfire75369:mozilla.org> What's the solution then?

The solution is either to never have cycles go through non-JS (I think Servo does this by always having JS reflectors and having ownership only apply to the reflectors?) or to break the cycles yourself, which is going to be difficult in general.

[09:08:35.0298] <Redfire>
```rs
pub struct URL {
	url: Url,
	heap: Box<Heap<*mut JSObject>>, // URLSearchParams
}
pub struct URLSearchParams {
	url: *mut Url,
 	heap: Box<Heap<*mut JSObject>>, // URL
}
```
Basically the structure I'm working with, each of these structs is stored in the reserved slot as a private value.

[09:10:45.0425] <Redfire>
I guess I could do an `Rc<RefCell<Url>>` so it wouldn't kill itself unnecessarily

[09:50:38.0529] <mgaudet>
I know that `undefined` is a binding in JS -- so you can construct a shadowing. As well, I know `undefined` if not shadowed lives in the global lexical environment. Some comments suggest further that the global lexical environment is mutable; but I can't figure out -how- to actually mutate the `undefined` binding. 

Essentially, what I'm trying to figure out is how it would be observable if instead of doing a `GetGName 'undefined'` (assuming no shadowing) we instead just pushed the op `Undefined` 

[10:38:05.0743] <iain>
mgaudet: The trick I used when [testing generation counts for global variables](https://phabricator.services.mozilla.com/D170962) was `evaluate` to add new bindings to the lexical global, but `evaluate("let undefined = 3")` gives an error message about redeclaring a non-configurable global property, so that doesn't seem to get anywhere.

[10:38:37.0550] <iain>
(Are you sure about `undefined` being on the global lexical? It looks to me like it lives on the global itself, although I'm not sure that makes a concrete difference)

[10:39:29.0756] <mgaudet>
So if it lived on the global, I would have expected `function f(x) { return x == undefined; }; window.undefined = 10; f(10)` to return true... but so far that didn't work

[10:39:37.0593] <iain>
It's not writable

[10:39:40.0889] <mgaudet>
so I thought it was the global lexical 

[10:39:53.0799] <iain>
```
js> Object.getOwnPropertyDescriptors(this).undefined
({value:(void 0), writable:false, enumerable:false, configurable:false})
```

[10:41:11.0464] <mgaudet>
Hmm. But it's not configurable.... can that be bypassed at all? 

[10:42:19.0449] <mgaudet>
(So far, patching NameOpEmitter to just emit `Undefined` is working on jstests and jit-tests..._

[10:45:12.0370] <mgaudet>
(For context, I was looking into how we could emit `IsNullOrUndefined` for user code, but the fact that undefined is a binding has caused some consternation. The fact that we see to be able to tell when undefined is actually the `undefined` we expect is thus-far helpful. I do however keep waiting for the language to jump out from behind a corner and beat me senseless with something tho) 

[10:52:19.0360] <mgaudet>
 * (For context, I was looking into how we could emit `IsNullOrUndefined` for user code, but the fact that undefined is a binding has caused some consternation. The fact that we seem to be able to tell when undefined is actually the `undefined` we expect is thus-far helpful. I do however keep waiting for the language to jump out from behind a corner and beat me senseless with something tho)

[11:13:39.0269] <iain>
In WarpBuilder we special-case `undefined`, `infinity`, and `NaN` to avoid looking them up on the global: https://searchfox.org/mozilla-central/source/js/src/jit/WarpBuilder.cpp#1852-1863

[11:14:04.0964] <iain>
 * In WarpBuilder we special-case `undefined`, `Infinity`, and `NaN` to avoid looking them up on the global: https://searchfox.org/mozilla-central/source/js/src/jit/WarpBuilder.cpp#1852-1863

[11:14:46.0521] <iain>
I can't think of a reason off the top of my head that we couldn't do that in the parser

[11:14:54.0859] <iain>
Maybe something terrible debugger-related?

[12:20:58.0978] <mgaudet>
Interesting pointer. Thank you for that :) 

[12:30:48.0222] <iain>
mgaudet: I'm assuming that we know at parse time whether non-syntactic scopes are involved?

[12:30:57.0109] <mgaudet>
Yes 

[12:31:05.0096] <mgaudet>
and we generate different bytecode as a result

[12:38:17.0486] <iain>
After a bit more code archaeology, the oldest version of this logic I can find is [here]([https://searchfox.org/mozilla-esr78/rev/283eca2156161574c38f4375d621f819128d52b9/js/src/ion/BaselineCompiler.cpp#660) in baseline](https://searchfox.org/mozilla-esr78/rev/82c1487dc74e020cd8f50f52a601c169dd28f87a/js/src/ion/IonBuilder.cpp#1986-1991)

[12:38:43.0068] <iain>
 * After a bit more code archaeology, the oldest version of this logic I can find is [here](https://searchfox.org/mozilla-esr78/rev/82c1487dc74e020cd8f50f52a601c169dd28f87a/js/src/ion/IonBuilder.cpp#1986-1991)

[12:39:17.0134] <iain>
Unfortunately there's no real discussion about it

[12:40:31.0812] <iain>
Note that baseline [also optimizes this](https://searchfox.org/mozilla-central/source/js/src/jit/BaselineCodeGen.cpp#3230-3248)

[12:40:42.0923] <iain>
(But not blinterp)

[12:45:03.0587] <mgaudet>
This feels like something we can fix in bytecode emission for sure. 

I have an idea on how to do the conditional folding still. Just have to write it out. 


2023-05-16
[05:24:29.0862] <davidj361>
Is there a reason why `JS_ReportErrorASCII` isn't catchable in JS?

[05:27:44.0804] <davidj361>
 * Is there a reason why `JS_ReportErrorASCII` isn't catchable in JS with a try catch block?

[06:46:01.0291] <jandem>
davidj361: it should be catchable in JS. Are you returning false/nullptr everywhere?

[06:47:30.0298] <jandem>
 * davidj361: it should be catchable in JS. Are you returning false/nullptr after calling it (and up the stack)?

[08:12:45.0477] <davidj361>
Thanks jandem

[12:09:42.0709] <TheQwertiest>
hey everyone!
a few questions regarding reserved slots:
- do I need to manually trace js objects placed in reserved slots?
- if no, do I need to manually clear js objects in reserved slots?
- if no, would GC detect the cycle properly if I place JS objects in each other slots?

[12:10:12.0730] <TheQwertiest>
 * hey everyone!
a few questions regarding reserved slots:

- do I need to manually trace js objects placed in reserved slots?
- if no, do I need to manually clear js objects in reserved slots?
- if no, would GC detect the cycle and clean up everything properly if I place JS objects in each other reserved slots?

[12:14:07.0861] <TheQwertiest>
 * hey everyone!
a few questions regarding reserved slots:

- do I need to manually trace js things placed in reserved slots?
- if no, do I need to manually clear js things in reserved slots?
- if no, would GC detect the cycle and clean up everything properly if I place JS objects in each other reserved slots?

[12:45:02.0850] <mgaudet>
TheQwertiest: So long as they are GC things in reserved slots, everything should be done correctly I believe! (PrivateGCThings would be the exception tho -- no idea how they're handled) 

[13:38:30.0466] <mgaudet>
Oof. Almost 8 minute wait for a try push ðŸ˜¬

[13:48:42.0482] <TheQwertiest>
> <@mgaudet:mozilla.org> TheQwertiest: So long as they are GC things in reserved slots, everything should be done correctly I believe! (PrivateGCThings would be the exception tho -- no idea how they're handled)

thanks!


2023-05-17
[00:51:56.0409] <canadahonk>
hey all, just wondering, is there any (particular) reason why https://bugzilla.mozilla.org/show_bug.cgi?id=1706124 isn't on by default? chrome ships it in 114 ;)

[00:54:40.0697] <jandem>
Ryan Hunt: ^

[00:55:29.0953] <canadahonk>
..nevermind, https://webassembly.org/roadmap/ is wrong :P

[00:56:02.0302] <canadahonk>
(or at least it's `value: true` in central)

[01:05:33.0667] <canadahonk>
for ref, https://bugzilla.mozilla.org/show_bug.cgi?id=1814421 (didn't find before either)

[01:09:44.0509] <canadahonk>
 * ..nevermind, https://webassembly.org/roadmap/ is wrong :P sent a PR to update

[01:09:56.0467] <canadahonk>
 * for ref, https://bugzilla.mozilla.org/show\_bug.cgi?id=1814421 (didn't find before either). sorry for the trouble

[02:01:36.0884] <jandem>
no worries

[07:00:53.0495] <liam_g>
If I'm using JS::Construct, how do I set the `this` value of the newly constructed object?

[07:18:00.0963] <jandem>
the engine creates the `this` object for you

[07:18:32.0243] <liam_g>
Yeah I was just coming to realise that. The question makes no sense ðŸ˜†

[07:21:47.0962] <liam_g>
Im having trouble with an object constructed using JS::Construct. It doesn't seem to recognise the global functions. 

[07:21:48.0247] <liam_g>
It's supposed to just take whatever global object is defined inside the Context, right?

[07:22:09.0246] <jandem>
are you calling a JS function?

[07:22:50.0085] <jandem>
it will switch to the global of the function you're calling

[07:23:14.0169] <liam_g>
It's a class constructor.

[07:25:50.0523] <liam_g>
Looks like I need to poke around more as I'm not really understanding what's going on. Sorry for the noise.

[07:25:50.0900] <jandem>
the global should be the one that was used when evaluating the class definition

[08:54:22.0701] <jonco>
@allstarschh: ping

[08:54:42.0923] <@allstarschh>
 jonco oh coming,  I am watching the MOCO meeting

[10:03:12.0971] <nbp>
jandem: iain: our current usage of `jmp_rip` is no longer an option with X-only. Do you have a preference over having a background set of pages which only contains the rip+constant, or would you prefer to have a read-only page in the middle of the executable pages which made to hold the constant without exec-flag?

[10:04:01.0974] <nbp>
Today we have slightly less than 2G, which makes it possible to allocate constants in an alternate space, at the huge cost of memory, but simplicity.

[10:24:48.0227] <nbp>
Another alternative would be to dedicate a register to be used as a constant index, but it would have to be restored each time we come back from a call (as volatile registers are most frequently used for arguments)

[10:29:39.0645] <jandem>
nbp: is that for the jump tables? the baseline interpreter uses leaq_rip I think

[10:30:02.0014] <nbp>
yes, the jmp_rip instruction used for the "far" jumps.

[10:32:42.0508] <jandem>
good question. I'm not sure what the best way to fix this is. Maybe worth checking how other projects worked around this? 

[10:32:42.0602] <nbp>
Yes rip-relative in general would have to be moved away from the code if we want X-only in the future.

[10:33:52.0525] <nbp>
This would also be nice to have even for architecture which do not have X-only I suppose.

[14:50:00.0097] <mgaudet>
I find myself surprised that X-only would disallow `jmp_rip`... that feels like a weird restriction!

[14:50:25.0769] <mgaudet>
Or do we expect to patch these offsets when we use IP relative jumps?


2023-05-18
[06:25:06.0234] <bwc>
So I'm implementing one of these, for a WritableStream that JS will be writing DOM objects to: https://searchfox.org/mozilla-central/rev/11a4d97a7b5cdfa133f4bda4525649f651703018/dom/streams/UnderlyingSinkCallbackHelpers.h#38-40

[06:25:42.0949] <bwc>
What's the right way to get from the JS::Value to the DOM object?

[06:27:06.0101] <bwc>
(if it matters, the DOM objects we want to get out of there are ones we created in c++, and passed to JS via a ReadableStream for modification)

[06:37:16.0837] <iain>
bwc: You can get a JSObject out of a JSValue using [these](https://searchfox.org/mozilla-central/source/js/public/Value.h#938-958) (assuming that you put an object in the value in the first place. Assuming your objects are subclasses of JSObject, you can downcast them with `obj.to<YourDOMObjectType>()`.

[06:57:24.0931] <bwc>
They are not subclasses of JSObject.

[06:58:43.0441] <bwc>
They're nsISupports/nsWrapperCache implementations of a webidl interface.

[07:19:18.0552] <bwc>
Is this what I want, maybe? https://searchfox.org/mozilla-central/source/dom/bindings/BindingUtils.h#140

[07:20:07.0792] <mccr8>
> <@bwc:mozilla.org> Is this what I want, maybe? https://searchfox.org/mozilla-central/source/dom/bindings/BindingUtils.h#140

Yeah probably. Also this is really a #dom:mozilla.org question and not a SpiderMonkey question. ðŸ˜„

[07:20:56.0460] <mccr8>
Well, there's a few different unwrap helpers like that, I think. I'm not sure what exactly is the right one.

[07:21:25.0604] <mccr8>
This one might be better? https://searchfox.org/mozilla-central/search?q=symbol:_ZN7mozilla3dom15UnwrapDOMObjectEP8JSObject&redirect=false

[07:21:26.0996] <bwc>
> <@mccr8:mozilla.org> Well, there's a few different unwrap helpers like that, I think. I'm not sure what exactly is the right one.

Yeah, I noticed... just making sure I don't use the wrong one.

[07:22:11.0082] <mccr8>
Hmm that one I linked to is used in some internal method so maybe I'm wrong.

[07:22:29.0724] <mccr8>
Anyways I'd ask in the DOM channel and somebody might actually have a correct answer for you.

[07:22:38.0095] <bwc>
Yeah, that one seems to do less checking.

[10:28:32.0902] <davidj361>
what's the difference between `JS_ValueToObject` and `.toObject()`?

[10:34:15.0668] <iain>
One takes a raw JSValue and gives back a raw JSObject*, the other takes a handle to a rooted Value and a mutable handle to a rooted Object and stores the object in the mutable handle

[11:44:01.0276] <tcampbell>
`JS_ValueToObject` will actually do a coercion if the value is a number/string/etc, while `toObject` has a debug assert that the Value is already an object pointer and crashes if the value were somethign like a string

[12:09:28.0712] <sfink>
> <@mgaudet:mozilla.org> So if it lived on the global, I would have expected `function f(x) { return x == undefined; }; window.undefined = 10; f(10)` to return true... but so far that didn't work

Does this count: `with({undefined: 3}) { print(undefined) }`

[12:14:47.0581] <sfink>
oh, you only care about `GetGNamme`. Never mind.

[12:14:52.0370] <mgaudet>
For my purposes, no :) I think in that situation we'd register the existence of a non-syntactic scope. In this case, `undefined` is a binding which shadows the global one. 

For my purposes, the fact that `undefined` lives on the global(lexical environment?) and is not configurable is sufficient as it means that we can assume if we find a name that is `undefined` and the lookup tells us it will be taken from the global, we can assume it has the `undefined` value 

[12:14:55.0256] <sfink>
 * oh, you only care about `GetGName`. Never mind.

[12:15:32.0122] <mgaudet>
Yeah -- and this used to be special cased by Baseline and Warp; all I did was sink that logic into the bytecode emitter.

[12:24:08.0363] <iain>
"...lives on the global(lexical environment?)": the global. The global lexical environment is a separate thing that isn't visible from user code. Variables defined with `let` and `const` live in the global lexical environment, and can't be accessed via the global; variables defined with `var` are properties on the global object, because Brendan Eich makes bad choices.


2023-05-19
[06:33:45.0658] <liam_g>
I have a class which overrides BaseProxyBandler, and I'm a bit confused about when the various virtual functions are called for getting and setting properties. Right now, I'm overriding `getOwnPropertyDescriptor()`, and all of the get and set functions seem to go through that. So far so good. But now I want some extra flexibility with setting properties, so I am overriding `set()`, but this function never gets called. It's the same with `defineProperty()`. Why is that?

[06:34:27.0053] <liam_g>
I have made sure that `hasPrototype` is false.

[07:16:53.0664] <evilpie>
liam_g: so e.g. `proxy.a = 1` doesn't invoke the set hook?

[07:24:08.0592] <liam_g>
That's right. It goes through getOwnPropertyDescriptor(), but not through set()

[07:25:58.0473] <evilpie>
Show your code

[07:26:55.0722] <liam_g>
oof, there's a lot of it.

[07:27:19.0063] <liam_g>
just a sec

[07:27:21.0535] <evilpie>
otherwise just set through Proxy::set

[07:27:26.0896] <evilpie>
 * otherwise just step through Proxy::set

[07:29:32.0375] <liam_g>
Here's the code: https://pastebin.mozilla.org/ZgvasStW

[07:30:48.0379] <liam_g>
> <@evilpie:mozilla.org> otherwise just step through Proxy::set

I have trouble with that because Visual Studio will only let me set a breakpoint in my own code. I can step into Spidermonkey code, but I can't set a breakpoint there.

[07:33:33.0794] <evilpie>
Not sure why it doesn't work. You probably want to invest in getting a working debugger

[08:01:19.0417] <liam_g>
I thought it was normal that Visual studio couldn't set a breakpoint inside a dll. If anyone knows how, I'd love to hear it.

[08:02:42.0442] <liam_g>
But i think I'm just getting caught up here with some the wrong settings or overrides of the BaseProxyHandler class. There are so many virtual functions and optimisations. In particular, the hasPrototype argument says that it will bypass the set() methods. I've switched that off, but it still doesn't seem to work. I must be missing something.

[10:30:33.0977] <nbp>
jandem: mgaudet: iain: Looking around, I think what makes sense would be to reserve a region as large as the code region where we can allocate constant pages as needed. Thus the code would still use RIP but all the constants would be shove into these constant regions which would be flagged as read-only while the code is X-only.

Looking at ARM64, this might also be applicable if we wanted to remove constant pools, which sounds highly appealing to me! The cost is an extra `ADRP` instruction per constant load.

Allocating these constant regions would add a bit more complexity to our JIT code allocations, but this sounds manageable. There might be corner cases due to the signess of relative offset, implying that we might have constant before and after our code region on x64 if we want to avoid fragmentation cases (when the JIT area is full, or we could just discard this case) 



2023-05-22
[03:15:49.0817] <l11d>
nbp: regarding X-only, do you have a scenario in mind where this feature would make the life of adversaries significantly harder? at the end of the day, an (in-process) JIT always requires some writable pages which are later made executable. the v8 folks even intend to keep JIT-pages rwx all the time due (1) little/no security advantage of transitioning from rw- to r-x (2) at some non-negligible  performance cost due to repeatedly calling `mprotect`

[04:25:28.0694] <nbp>
l11d: The problem of Jit spraying is that an adversary can inject instructions into executable pages. However, to make use of it, the attacker should know the address of it.
Instead of doing constant blinding, I was thinking of making the position of immediate constants random.
Combined with X-only memory, this reduces the success of making a valid jump by half, for each immediate constant.

[04:26:37.0185] <nbp>
When we have an immediate constant which is not under our control, we generate (noop+const) or (const+noop), one of the tricky part might be to ensure that noop crashes if ever jump into.

[05:30:36.0525] <l11d>
nbp: the root-cause of vulnerabilities gives adversaries a first-order primitive (e.g., limited OOB read/write), which in turn may be escalated to stronger second-order primitives (e.g., rw-access to the entire address space). violating CFI by jumping into the middle of the instruction stream is one of the last steps of a content-compromise. at this point (freely jumping into the middle of the instruction stream), the exploitation primitives are super powerful and X-only seems rather unlikely to tip the balance in favor of defenders. e.g., with interactive rw access to the address space, one can write to pages which will be X-only in the future. this essentially allows to emit any shell-code one pleases. alternatively, adversaries can craft a ROP/JOP payload that generically achieves code execution within content. considering the amount of code within libxul, the number of ROP/JOP chainable gadgets is vast.
reducing the number of bugs or, even better, eliminating a bug class altogether may be much better value for money. in the context of jit-compilation, this is could be something like the heap-sandbox as adversaries can no longer escalate jit-bugs to an interactive rw access to the entire address space. for stronger CFI, Intel IBT (https://lwn.net/Articles/889475/) and ARM BTI might be worth looking into. as these are relatively new technologies, their defensive value remains to be seen

[05:36:56.0337] <wraitii>
Hello everyone, I'm looking into Upgrading 0 A.D. from 91 to SM 102. I'm running into an odd issue. We are JS::Execute-ing some code, and I get an assertion error in `NearestEnclosingExtensibleLexicalEnvironment` that there is no env (inside a `GlobalOrEvalDeclInstantiation`). The cause, as far as I can tell, is that we `JS_DeepFreeze` a global variable. There doesn't seem to be anything else wrong or special. Any clue what might have caused this to break now? 

[06:05:01.0670] <evilpie>
jandem: You could add #spidermonkey-reviewers to https://firefox-source-docs.mozilla.org/contributing/reviews.html

[06:05:15.0249] <evilpie>
 * jandem:  You could add #spidermonkey-reviewers to https://firefox-source-docs.mozilla.org/contributing/reviews.html

[06:09:02.0891] <nbp>
l11d: My understanding was that to jump to some JIT code one needed only a stack overflow, to read the return addresses and replace them, and having written some code in a known location within executable pages.
Thus I am not sure about the second-order being necessary as you describe it.

[06:15:42.0479] <jandem>
evilpie: good idea. I'll look into it

[06:18:03.0062] <l11d>
regarding the scenario you have in mind: are you concerned about an adversary with a linear stack-based buffer overflow in non-jitted code that later jumps to shell-code inside jitted code? backward-edge protection (essentially, preventing return address overrides) is something that hardware-assisted shadow-stacks provide (like Intel CET). this does require (1) compiler-support and (2) JIT-support.

[06:20:49.0885] <nbp>
which we do not have yet.

[06:21:16.0267] <nbp>
also our JIT kind of rely on this capability for implementing bailouts.

[07:09:54.0320] <l11d>

I don't know how bailouts are implemented in detail. longjmp/setjmp work though (with CET), maybe bailouts are not so different?
coming back to the scenario mentioned above: (1) leak the address of jit-code and (2) override a stack-stored address/function pointer with the leaked address. if this would be some linear overflow it should be caught by stack-cookies (unless one also can leak the stack-cookie). if the adversary has the ability to write at chosen offsets (hence bypassing the stack-cookie) this becomes quite difficult to defend against. while directly jumping to jitted code might not be possible with X-only, it seems unlikely that there won't be a viable exploitation path. the life of adversaries got more difficult only once (to figure out how to build a nice ROP/JOP or escalate to a more powerful primitive) but you have to both invest into the feature and need to continuously maintain it

[07:19:26.0182] <nbp>
Welcome to the world of defensive security. The adversary has to find one flaw, we have to close all of them. In the mean time we can just make the life harder.


2023-05-23
[18:54:56.0433] <liam_g>
Are there any Spidermonkey methods for creating and parsing Xml? DOMParser and XMLSerializer don't seem to be there.

[19:20:29.0769] <sfink>
no, SM doesn't have do any XML processing anywhere.

[19:20:38.0582] <sfink>
 * no, SM doesn't do any XML processing anywhere.

[19:26:18.0431] <Gregory Pappas (:gregp)>
E4X :-)

[19:27:14.0340] <sfink>
...anymore.

[20:01:15.0257] <liam_g>
OK thanks, I'll stick with JSON.

[21:02:52.0773] <jdm>
Hello! Servo's embedding of spidermonkey is showing unexpected behaviour, but I'm not sure where to start looking to track it down. Full details in https://github.com/servo/servo/issues/29770, but the short form is that doing `class Klass extends EventTarget {}` and then `let a = new Klass();` gives me a value that is an EventTarget, not a Klass.

[03:22:07.0634] <Ms2ger>
I deny responsibility

[05:12:15.0249] <jandem>
jdm: I think the created object should be an `EventTarget` (have that JSClass), but it should have `Klass.prototype` on its proto chain

[05:12:32.0326] <jandem>
I think in Firefox that's implemented [here](https://searchfox.org/mozilla-central/rev/2d678a843ceab81e43f7ffb83212197dc10e944a/dom/bindings/BindingUtils.cpp#3667)

[05:14:44.0192] <jandem>
`GetPrototypeFromConstructor` in the spec: https://tc39.es/ecma262/#sec-getprototypefromconstructor

[05:15:02.0115] <jandem>
 * jdm: the created object should be an `EventTarget` (have that JSClass), but it should have `Klass.prototype` on its proto chain

[05:15:46.0370] <jandem>
 * jdm: the created object should be an `EventTarget` (have that JSClass), but it should have `Klass.prototype` as its proto (which will have `EventTarget.prototype` as its proto)

[05:17:18.0210] <jandem>
 * jdm: the created object should be an `EventTarget` (have that JSClass), but it should have `Klass.prototype` as its proto (which will have `EventTarget.prototype` as proto)

[05:20:50.0030] <jandem>
(so the `EventTarget` constructor needs to look at `newTarget.prototype` if `newTarget != callee` to determine the proto for the new object. In this case it should be `Klass.prototype`)

[05:23:35.0653] <jandem>
 * (so the `EventTarget` constructor needs to look at `newTarget.prototype` to determine the proto for the new object. In this case it should be `Klass.prototype`)

[07:28:41.0921] <tcampbell>
Hey sefeng, it looks like arai will take the final bugs to switch utility process to new parser APIs.

[07:29:03.0762] <tcampbell>
( arai , can you assign them to yourself)

[07:41:46.0145] <jlink>
How do I get a build with JS_JITSPEW enabled? Is there something that I need to put in my mozconfig file for that?

[07:44:02.0356] <sefeng>
tcampbell: ah okay, thanks. I should wait for that before trying to migrate to the new API?  

[07:44:37.0633] <tcampbell>
sefeng: Arai has prototype patches to migrate to new API and can do that part for you as well

[07:44:54.0913] <sefeng>
ah that's awesome! 

[10:29:47.0965] <davidj361>
Is it even possible to see JS values and such in runtime debugging? like `entries` or `tmp`? Because when I expand these in the variable window I only can see in `private` `asBits_`

[10:31:42.0999] <mgaudet>
I'm not sure how you could wire it into vscode; but if you have a debugger window, calling `JS::DumpValue` would likely help

[10:32:12.0383] <davidj361>
I'm getting a segfault so I'm trying to see what all these JS values contain and see what's actually happening

[11:20:21.0915] <Bryan Thrall [:bthrall]>
davidj361: I don't know if vscode's variable window will use them, but there are [gdb pretty printers for things like JSValue](https://searchfox.org/mozilla-central/source/js/src/gdb/README)

[14:25:11.0932] <Tim>
mgaudet: I think https://phabricator.services.mozilla.com/D174699 is ready to land; Peter signed off and I rebased it. (Try build currently running)

[14:34:12.0233] <mgaudet>
Tim: Awesome. If you send me a link to your try build, I'll queue it for landing tomorrow morning 

[15:00:44.0627] <Tim>
> <@mgaudet:mozilla.org> Tim: Awesome. If you send me a link to your try build, I'll queue it for landing tomorrow morning

Sure, the try build is https://treeherder.mozilla.org/jobs?repo=try&revision=b611cde1999598e6fae7d4b4679b5f95fc059b21 . There are two test failures so far that look unrelated. (I tried retriggering them anyway, but I don't think they've re-run yet.)

[15:01:31.0971] <mgaudet>
Awseome. That's good enough for me to queue it for landing. Done :) 

[15:16:57.0119] <Tim>
> <@mgaudet:mozilla.org> Awseome. That's good enough for me to queue it for landing. Done :)

Thanks!

[15:21:45.0194] <Tim>
mgaudet btw there are two lint warnings ( https://phabricator.services.mozilla.com/D174699#5901456 ) about the test names in mochitest.ini and chrome.ini not being in alphabetical order. I assume those are ignorable since it was already like that

[15:48:54.0130] <mccr8>
> <@tjc:igalia.com> mgaudet btw there are two lint warnings ( https://phabricator.services.mozilla.com/D174699#5901456 ) about the test names in mochitest.ini and chrome.ini not being in alphabetical order. I assume those are ignorable since it was already like that

yeah warnings are fine

[15:50:02.0661] <mccr8>
I wouldn't mess up the order if it was already okay but it is way out of scope to fix the ordering of a zillion files in your patch.

[15:52:14.0230] <Tim>
> <@mccr8:mozilla.org> I wouldn't mess up the order if it was already okay but it is way out of scope to fix the ordering of a zillion files in your patch.

I wish the lint tool was granular enough to only apply to the diffs in the outgoing commit, rather than the entire file. I guess that might be hard to implement, though

[15:53:02.0451] <Tim>
not a big problem in this case, but sometimes there's a mix of warnings about issues that already existed, and warnings about code I actually added, and it's easy to miss the warnings I actually need to address


2023-05-24
[19:06:26.0581] <jlink>
What are some of the reasons why a script would re-compile other than due to bailouts? The only other reason that I am aware of is a compacting GC. Are there more?

[19:09:03.0777] <jlink>
(For those who might want more context: I'm looking into why some scripts seem to be getting compiled many times when in a particular Speedometer3 benchmark. In the first script that I'm looking at it gets compiled, bails out 10 times due to TranspiledCacheIR, gets re-compiled and has a shape guard changed to a megamorphic cache look-up, and then gets compiled a third time and produces the exact same thing that it produced the second time.)

[19:09:59.0579] <jlink>
 * (For those who might want more context: I'm looking into why some scripts seem to be getting compiled many times when in a particular Speedometer3 benchmark. In the first script that I'm looking at it gets compiled, bails out 10 times due to TranspiledCacheIR, gets re-compiled and has a shape guard + fixed slot load changed to a megamorphic cache look-up, and then gets compiled a third time and produces the exact same thing that it produced the second time.)

[19:10:56.0014] <jlink>
The first bailout seems a little fishy to me (did we really encounter a new shape after it having run consistently with only a single previous shape before?) but the third re-compile just seems incorrect.

[19:11:04.0850] <jlink>
 * The first bailout seems a little fishy to me (did we really encounter a new shape after it having run consistently with only a single previous shape before?) but the third re-compile just seems unnecessary.

[19:11:38.0775] <jlink>
 * (For those who might want more context: I'm looking into why some scripts in a particular Speedometer3 benchmark seem to be getting compiled many times. In the first script that I'm looking at it gets compiled, bails out 10 times due to TranspiledCacheIR, gets re-compiled and has a shape guard + fixed slot load changed to a megamorphic cache look-up, and then gets compiled a third time and produces the exact same thing that it produced the second time.)

[19:12:04.0695] <jlink>
 * (For those who might want more context: I'm looking into why some scripts in a particular Speedometer3 benchmark seem to be getting compiled many times. For the first script that I'm looking at - it gets compiled, bails out 10 times due to TranspiledCacheIR, gets re-compiled and has a shape guard + fixed slot load changed to a megamorphic cache look-up, and then gets compiled a third time and produces the exact same thing that it produced the second time.)

[19:24:51.0470] <sfink>
non-compacting GCs can also discard jit code

[19:25:48.0477] <sfink>
see [GCRuntime::shouldPreserveJITCode](https://searchfox.org/mozilla-central/rev/8e1b221afcdae76284b1439c547b032d1f84d236/js/src/gc/GC.cpp#2247-2277) for example.

[19:38:46.0050] <jlink>
Thanks Steve, I'll take a look.

[20:29:41.0036] <jlink>
Is that function (GCRuntime::shouldPreserveJITCode()) only called when we're doing a GC? If so, we're doing GC _a lot_.
Here is (the last bit of) the call stack where I'm seeing it being called:

>	xul.dll!js::gc::GCRuntime::shouldPreserveJITCode(JS::Realm * realm, const mozilla::TimeStamp & currentTime, JS::GCReason reason, bool canAllocateMoreCode, bool isActiveCompartment) Line 2308	C++
 	xul.dll!js::gc::GCRuntime::endPreparePhase(JS::GCReason reason) Line 2781	C++
 	xul.dll!js::gc::GCRuntime::incrementalSlice(js::SliceBudget & budget, JS::GCReason reason, bool budgetWasIncreased) Line 3645	C++
 	xul.dll!js::gc::GCRuntime::gcCycle(bool nonincrementalByAPI, const js::SliceBudget & budgetArg, JS::GCReason reason) Line 4236	C++
 	xul.dll!js::gc::GCRuntime::collect(bool nonincrementalByAPI, const js::SliceBudget & budget, JS::GCReason reason) Line 4420	C++


[20:36:26.0946] <jlink>
Is there any _easy_ way to tell if given script is having its compiled Ion code tossed out (whether due to GC or something else)? Is there a function on the JSScript that gets called when that happens?

[20:57:07.0756] <mstange>
jlink: Do you have a Linux machine so that you can use rr for debugging? It makes it easier to answer these kinds of questions because you can set a watchpoint on a variable and reverse-continue, and youâ€™ll see who last modified that variable 

[21:59:13.0246] <Chris Peterson (:cpeterson)>
Were there any GC changes in 114 that might have caused crashes when RefPtr and RefCounted atomically decrement ref counts? https://bugzilla.mozilla.org/show_bug.cgi?id=1834685

[21:59:53.0597] <Chris Peterson (:cpeterson)>
 * Were there any GC changes in 114 that might have caused an increase in crashes when RefPtr and RefCounted atomically decrement ref counts? https://bugzilla.mozilla.org/show\_bug.cgi?id=1834685

[01:23:05.0859] <jonco>
Chris Peterson (:cpeterson): RefPtr isn't usuallly GC related, but those crashes do seem to be JS related, mostly wasm.  I've commented in the bug.

[02:42:52.0854] <Redfire>
Is there any reason your callback would get called multiple times?
I'm creating a promise executor from a callback and then adding reactions (fulfilled + rejected) with two more callbacks. Somewhere along the line, the callback is getting called multiple times and I'm confused.

[02:45:23.0314] <Redfire>
libffi-rs is complaining with `FnOnce closure already used`

[06:48:55.0213] <jlink>
> <@mstange:mozilla.org> jlink: Do you have a Linux machine so that you can use rr for debugging? It makes it easier to answer these kinds of questions because you can set a watchpoint on a variable and reverse-continue, and youâ€™ll see who last modified that variable

Hi Markus, I don't have access to a Linux machine. Visual Studio does have data breakpoints to find out who modifies a location in memory _in the future_. The problem is that I'm not sure what data to be looking at yet. (That is, I don't know what exactly happens when the GC runs and throws away Ion code. From what I understand the JSScripts are persistent but I think that something accessible from the script will get null'd back out when the GC throws the Ion-compiled code away.) I probably just need to track the data that BaseScript ultimately uses to answer to hasIonScript() - that will tell me when/why the Ion script is going away.

[06:53:44.0047] <Redfire>
> <@redfire75369:mozilla.org> Is there any reason your callback would get called multiple times?
> I'm creating a promise executor from a callback and then adding reactions (fulfilled + rejected) with two more callbacks. Somewhere along the line, the callback is getting called multiple times and I'm confused.

Ok that was entirely my mistake. The function ptr became invalid when the function returned which is why only adding reactions failed. They were done after the function returned while creating a new promise with an executor is done while that's still on the stack.

[06:55:48.0985] <mstange>
jlink: Yeah I suppose youâ€™ll need to find the right place to set the watchpoint on either way. But believe me, once youâ€™ve experienced time travel debugging itâ€™s hard to go back. You can also try WinDebugâ€™s Time Travel Debugging

[07:04:01.0689] <denispal>
jlink: I think this is where we throw away the Ion code https://searchfox.org/mozilla-central/rev/a4fd6daad3a4123d995478467c1274653b283801/js/src/jit/Ion.cpp#2585

[07:12:50.0994] <Redfire>
```rs
Assertion failure: !IsInsideNursery(thing), at C:/Users/Redfire/.cargo/git/checkouts/mozjs-0f28a5f34a8f25e0/bb4942c/mozjs/mozjs/js/src/gc/GC.cpp:4746
#01: js::gc::ClearEdgesTracer::onEdge<JSObject> (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\GC.cpp:4746)
#02: js::GenericTracerImpl<js::gc::ClearEdgesTracer>::onObjectEdge (C:\Users\Redfire\spiderfire\target\debug\build\mozjs_sys-277341a3d9bd2227\out\build\dist\include\js\TracingAPI.h:219)
#03: js::gc::TraceEdgeInternal (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Tracer.h:106)
#04: TraceExternalEdgeHelper<JSObject *> (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Marking.cpp:380)
#05: js::gc::TraceExternalEdge (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Marking.cpp:406)
#06: JS::TraceEdge<JSObject *> (C:\Users\Redfire\spiderfire\target\debug\build\mozjs_sys-277341a3d9bd2227\out\build\dist\include\js\TracingAPI.h:350)
#07: CallObjectTracer (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\jsglue.cpp:886)
#08: mozjs::gc::trace::impl$1::trace (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:48)
#09: mozjs::gc::trace::RootedTraceableSet::trace (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:363)
#10: mozjs::gc::trace::trace_traceables::closure$0 (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:370)
#11: std::thread::local::LocalKey<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet> >::try_with<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet>,mozjs::gc::trace::trace_traceables::closure_env$0,tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\thread\local.rs:446)
#12: std::thread::local::LocalKey<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet> >::with<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet>,mozjs::gc::trace::trace_traceables::closure_env$0,tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\thread\local.rs:422)
#13: mozjs::gc::trace::trace_traceables (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:372)
#14: js::gc::GCRuntime::traceEmbeddingBlackRoots (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\RootMarking.cpp:377)
#15: js::gc::GCRuntime::finishRoots (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\RootMarking.cpp:439)
#16: JSRuntime::destroyRuntime (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\vm\Runtime.cpp:257)
#17: js::DestroyContext (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\vm\JSContext.cpp:226)
#18: JS_DestroyContext (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\jsapi.cpp:400)
#19: mozjs::rust::impl$11::drop (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\rust.rs:419)
#20: core::ptr::drop_in_place<mozjs::rust::Runtime> (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\ptr\mod.rs:490)
#21: cli::evaluate::eval_module::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\evaluate.rs:100)
#22: cli::commands::run::run::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\commands\run.rs:17)
#23: cli::commands::handle_command::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\commands\mod.rs:49)
#24: cli::main::async_block$0 (C:\Users\Redfire\spiderfire\cli\src\main.rs:64)
#25: core::future::future::impl$1::poll<ref_mut$<enum2$<cli::main::async_block_env$0> > > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\future\future.rs:126)
#26: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:541)
#27: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:541)
#28: tokio::runtime::scheduler::current_thread::Context::enter<enum2$<core::task::poll::Poll<tuple$<> > >,tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:350)
#29: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:540)
#30: tokio::runtime::scheduler::current_thread::impl$8::enter::closure$0<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:615)
#31: tokio::macros::scoped_tls::ScopedKey<tokio::runtime::scheduler::current_thread::Context>::set<tokio::runtime::scheduler::current_thread::Context,tokio::runtime::scheduler::current_thread::impl$8::enter::closure_env$0<tokio::runtime::scheduler::current_thr (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\macros\scoped_tls.rs:61)
#32: tokio::runtime::scheduler::current_thread::CoreGuard::enter<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:615)
#33: tokio::runtime::scheduler::current_thread::CoreGuard::block_on<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:530)
#34: tokio::runtime::scheduler::current_thread::CurrentThread::block_on<enum2$<cli::main::async_block_env$0> > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:154)
#35: tokio::runtime::runtime::Runtime::block_on<enum2$<cli::main::async_block_env$0> > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\runtime.rs:302)
#36: cli::main (C:\Users\Redfire\spiderfire\cli\src\main.rs:64)
#37: core::ops::function::FnOnce::call_once<void (*)(),tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\ops\function.rs:250)
#38: std::sys_common::backtrace::__rust_begin_short_backtrace<void (*)(),tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\sys_common\backtrace.rs:137)
#39: std::rt::lang_start::closure$0<tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\rt.rs:166)
#40: std::rt::lang_start_internal (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc/library\std\src\rt.rs:148)
#41: std::rt::lang_start<tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\rt.rs:165)
#42: main[C:\Users\Redfire\spiderfire\target\debug\cli.exe +0x33d79]
#43: __scrt_common_main_seh (D:\a\_work\1\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl:288)
#44: BaseThreadInitThunk[C:\WINDOWS\System32\KERNEL32.DLL +0x17614]
#45: RtlUserThreadStart[C:\WINDOWS\SYSTEM32\ntdll.dll +0x526a1]
```
I'm trying to figure out why destroying the runtime is failing, and I'm really not sure

[07:13:00.0161] <Redfire>
 * ```cppAssertion failure: !IsInsideNursery(thing), at C:/Users/Redfire/.cargo/git/checkouts/mozjs-0f28a5f34a8f25e0/bb4942c/mozjs/mozjs/js/src/gc/GC.cpp:4746
#01: js::gc::ClearEdgesTracer::onEdge<JSObject> (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\GC.cpp:4746)
#02: js::GenericTracerImpl<js::gc::ClearEdgesTracer>::onObjectEdge (C:\Users\Redfire\spiderfire\target\debug\build\mozjs_sys-277341a3d9bd2227\out\build\dist\include\js\TracingAPI.h:219)
#03: js::gc::TraceEdgeInternal (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Tracer.h:106)
#04: TraceExternalEdgeHelper<JSObject *> (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Marking.cpp:380)
#05: js::gc::TraceExternalEdge (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Marking.cpp:406)
#06: JS::TraceEdge<JSObject *> (C:\Users\Redfire\spiderfire\target\debug\build\mozjs_sys-277341a3d9bd2227\out\build\dist\include\js\TracingAPI.h:350)
#07: CallObjectTracer (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\jsglue.cpp:886)
#08: mozjs::gc::trace::impl$1::trace (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:48)
#09: mozjs::gc::trace::RootedTraceableSet::trace (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:363)
#10: mozjs::gc::trace::trace_traceables::closure$0 (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:370)
#11: std::thread::local::LocalKey<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet> >::try_with<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet>,mozjs::gc::trace::trace_traceables::closure_env$0,tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\thread\local.rs:446)
#12: std::thread::local::LocalKey<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet> >::with<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet>,mozjs::gc::trace::trace_traceables::closure_env$0,tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\thread\local.rs:422)
#13: mozjs::gc::trace::trace_traceables (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:372)
#14: js::gc::GCRuntime::traceEmbeddingBlackRoots (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\RootMarking.cpp:377)
#15: js::gc::GCRuntime::finishRoots (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\RootMarking.cpp:439)
#16: JSRuntime::destroyRuntime (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\vm\Runtime.cpp:257)
#17: js::DestroyContext (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\vm\JSContext.cpp:226)
#18: JS_DestroyContext (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\jsapi.cpp:400)
#19: mozjs::rust::impl$11::drop (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\rust.rs:419)
#20: core::ptr::drop_in_place<mozjs::rust::Runtime> (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\ptr\mod.rs:490)
#21: cli::evaluate::eval_module::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\evaluate.rs:100)
#22: cli::commands::run::run::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\commands\run.rs:17)
#23: cli::commands::handle_command::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\commands\mod.rs:49)
#24: cli::main::async_block$0 (C:\Users\Redfire\spiderfire\cli\src\main.rs:64)
#25: core::future::future::impl$1::poll<ref_mut$<enum2$<cli::main::async_block_env$0> > > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\future\future.rs:126)
#26: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:541)
#27: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:541)
#28: tokio::runtime::scheduler::current_thread::Context::enter<enum2$<core::task::poll::Poll<tuple$<> > >,tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:350)
#29: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:540)
#30: tokio::runtime::scheduler::current_thread::impl$8::enter::closure$0<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:615)
#31: tokio::macros::scoped_tls::ScopedKey<tokio::runtime::scheduler::current_thread::Context>::set<tokio::runtime::scheduler::current_thread::Context,tokio::runtime::scheduler::current_thread::impl$8::enter::closure_env$0<tokio::runtime::scheduler::current_thr (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\macros\scoped_tls.rs:61)
#32: tokio::runtime::scheduler::current_thread::CoreGuard::enter<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:615)
#33: tokio::runtime::scheduler::current_thread::CoreGuard::block_on<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:530)
#34: tokio::runtime::scheduler::current_thread::CurrentThread::block_on<enum2$<cli::main::async_block_env$0> > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:154)
#35: tokio::runtime::runtime::Runtime::block_on<enum2$<cli::main::async_block_env$0> > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\runtime.rs:302)
#36: cli::main (C:\Users\Redfire\spiderfire\cli\src\main.rs:64)
#37: core::ops::function::FnOnce::call_once<void (*)(),tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\ops\function.rs:250)
#38: std::sys_common::backtrace::__rust_begin_short_backtrace<void (*)(),tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\sys_common\backtrace.rs:137)
#39: std::rt::lang_start::closure$0<tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\rt.rs:166)
#40: std::rt::lang_start_internal (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc/library\std\src\rt.rs:148)
#41: std::rt::lang_start<tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\rt.rs:165)
#42: main[C:\Users\Redfire\spiderfire\target\debug\cli.exe +0x33d79]
#43: __scrt_common_main_seh (D:\a\_work\1\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl:288)
#44: BaseThreadInitThunk[C:\WINDOWS\System32\KERNEL32.DLL +0x17614]
#45: RtlUserThreadStart[C:\WINDOWS\SYSTEM32\ntdll.dll +0x526a1]
```

I'm trying to figure out why destroying the runtime is failing, and I'm really not sure

[07:13:05.0783] <Redfire>
 * ```cpp
Assertion
#01: js::gc::ClearEdgesTracer::onEdge<JSObject> (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\GC.cpp:4746)
#02: js::GenericTracerImpl<js::gc::ClearEdgesTracer>::onObjectEdge (C:\Users\Redfire\spiderfire\target\debug\build\mozjs_sys-277341a3d9bd2227\out\build\dist\include\js\TracingAPI.h:219)
#03: js::gc::TraceEdgeInternal (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Tracer.h:106)
#04: TraceExternalEdgeHelper<JSObject *> (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Marking.cpp:380)
#05: js::gc::TraceExternalEdge (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Marking.cpp:406)
#06: JS::TraceEdge<JSObject *> (C:\Users\Redfire\spiderfire\target\debug\build\mozjs_sys-277341a3d9bd2227\out\build\dist\include\js\TracingAPI.h:350)
#07: CallObjectTracer (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\jsglue.cpp:886)
#08: mozjs::gc::trace::impl$1::trace (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:48)
#09: mozjs::gc::trace::RootedTraceableSet::trace (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:363)
#10: mozjs::gc::trace::trace_traceables::closure$0 (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:370)
#11: std::thread::local::LocalKey<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet> >::try_with<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet>,mozjs::gc::trace::trace_traceables::closure_env$0,tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\thread\local.rs:446)
#12: std::thread::local::LocalKey<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet> >::with<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet>,mozjs::gc::trace::trace_traceables::closure_env$0,tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\thread\local.rs:422)
#13: mozjs::gc::trace::trace_traceables (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:372)
#14: js::gc::GCRuntime::traceEmbeddingBlackRoots (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\RootMarking.cpp:377)
#15: js::gc::GCRuntime::finishRoots (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\RootMarking.cpp:439)
#16: JSRuntime::destroyRuntime (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\vm\Runtime.cpp:257)
#17: js::DestroyContext (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\vm\JSContext.cpp:226)
#18: JS_DestroyContext (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\jsapi.cpp:400)
#19: mozjs::rust::impl$11::drop (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\rust.rs:419)
#20: core::ptr::drop_in_place<mozjs::rust::Runtime> (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\ptr\mod.rs:490)
#21: cli::evaluate::eval_module::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\evaluate.rs:100)
#22: cli::commands::run::run::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\commands\run.rs:17)
#23: cli::commands::handle_command::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\commands\mod.rs:49)
#24: cli::main::async_block$0 (C:\Users\Redfire\spiderfire\cli\src\main.rs:64)
#25: core::future::future::impl$1::poll<ref_mut$<enum2$<cli::main::async_block_env$0> > > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\future\future.rs:126)
#26: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:541)
#27: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:541)
#28: tokio::runtime::scheduler::current_thread::Context::enter<enum2$<core::task::poll::Poll<tuple$<> > >,tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:350)
#29: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:540)
#30: tokio::runtime::scheduler::current_thread::impl$8::enter::closure$0<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:615)
#31: tokio::macros::scoped_tls::ScopedKey<tokio::runtime::scheduler::current_thread::Context>::set<tokio::runtime::scheduler::current_thread::Context,tokio::runtime::scheduler::current_thread::impl$8::enter::closure_env$0<tokio::runtime::scheduler::current_thr (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\macros\scoped_tls.rs:61)
#32: tokio::runtime::scheduler::current_thread::CoreGuard::enter<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:615)
#33: tokio::runtime::scheduler::current_thread::CoreGuard::block_on<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:530)
#34: tokio::runtime::scheduler::current_thread::CurrentThread::block_on<enum2$<cli::main::async_block_env$0> > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:154)
#35: tokio::runtime::runtime::Runtime::block_on<enum2$<cli::main::async_block_env$0> > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\runtime.rs:302)
#36: cli::main (C:\Users\Redfire\spiderfire\cli\src\main.rs:64)
#37: core::ops::function::FnOnce::call_once<void (*)(),tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\ops\function.rs:250)
#38: std::sys_common::backtrace::__rust_begin_short_backtrace<void (*)(),tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\sys_common\backtrace.rs:137)
#39: std::rt::lang_start::closure$0<tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\rt.rs:166)
#40: std::rt::lang_start_internal (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc/library\std\src\rt.rs:148)
#41: std::rt::lang_start<tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\rt.rs:165)
#42: main[C:\Users\Redfire\spiderfire\target\debug\cli.exe +0x33d79]
#43: __scrt_common_main_seh (D:\a\_work\1\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl:288)
#44: BaseThreadInitThunk[C:\WINDOWS\System32\KERNEL32.DLL +0x17614]
#45: RtlUserThreadStart[C:\WINDOWS\SYSTEM32\ntdll.dll +0x526a1]
```

I'm trying to figure out why destroying the runtime is failing, and I'm really not sure

[07:13:18.0284] <Redfire>
 * ```cpp
Assertion failure: !IsInsideNursery(thing), at C:/Users/Redfire/.cargo/git/checkouts/mozjs-0f28a5f34a8f25e0/bb4942c/mozjs/mozjs/js/src/gc/GC.cpp:4746

#01: js::gc::ClearEdgesTracer::onEdge<JSObject> (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\GC.cpp:4746)
#02: js::GenericTracerImpl<js::gc::ClearEdgesTracer>::onObjectEdge (C:\Users\Redfire\spiderfire\target\debug\build\mozjs_sys-277341a3d9bd2227\out\build\dist\include\js\TracingAPI.h:219)
#03: js::gc::TraceEdgeInternal (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Tracer.h:106)
#04: TraceExternalEdgeHelper<JSObject *> (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Marking.cpp:380)
#05: js::gc::TraceExternalEdge (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Marking.cpp:406)
#06: JS::TraceEdge<JSObject *> (C:\Users\Redfire\spiderfire\target\debug\build\mozjs_sys-277341a3d9bd2227\out\build\dist\include\js\TracingAPI.h:350)
#07: CallObjectTracer (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\jsglue.cpp:886)
#08: mozjs::gc::trace::impl$1::trace (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:48)
#09: mozjs::gc::trace::RootedTraceableSet::trace (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:363)
#10: mozjs::gc::trace::trace_traceables::closure$0 (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:370)
#11: std::thread::local::LocalKey<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet> >::try_with<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet>,mozjs::gc::trace::trace_traceables::closure_env$0,tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\thread\local.rs:446)
#12: std::thread::local::LocalKey<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet> >::with<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet>,mozjs::gc::trace::trace_traceables::closure_env$0,tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\thread\local.rs:422)
#13: mozjs::gc::trace::trace_traceables (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:372)
#14: js::gc::GCRuntime::traceEmbeddingBlackRoots (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\RootMarking.cpp:377)
#15: js::gc::GCRuntime::finishRoots (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\RootMarking.cpp:439)
#16: JSRuntime::destroyRuntime (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\vm\Runtime.cpp:257)
#17: js::DestroyContext (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\vm\JSContext.cpp:226)
#18: JS_DestroyContext (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\jsapi.cpp:400)
#19: mozjs::rust::impl$11::drop (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\rust.rs:419)
#20: core::ptr::drop_in_place<mozjs::rust::Runtime> (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\ptr\mod.rs:490)
#21: cli::evaluate::eval_module::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\evaluate.rs:100)
#22: cli::commands::run::run::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\commands\run.rs:17)
#23: cli::commands::handle_command::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\commands\mod.rs:49)
#24: cli::main::async_block$0 (C:\Users\Redfire\spiderfire\cli\src\main.rs:64)
#25: core::future::future::impl$1::poll<ref_mut$<enum2$<cli::main::async_block_env$0> > > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\future\future.rs:126)
#26: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:541)
#27: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:541)
#28: tokio::runtime::scheduler::current_thread::Context::enter<enum2$<core::task::poll::Poll<tuple$<> > >,tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:350)
#29: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:540)
#30: tokio::runtime::scheduler::current_thread::impl$8::enter::closure$0<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:615)
#31: tokio::macros::scoped_tls::ScopedKey<tokio::runtime::scheduler::current_thread::Context>::set<tokio::runtime::scheduler::current_thread::Context,tokio::runtime::scheduler::current_thread::impl$8::enter::closure_env$0<tokio::runtime::scheduler::current_thr (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\macros\scoped_tls.rs:61)
#32: tokio::runtime::scheduler::current_thread::CoreGuard::enter<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:615)
#33: tokio::runtime::scheduler::current_thread::CoreGuard::block_on<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:530)
#34: tokio::runtime::scheduler::current_thread::CurrentThread::block_on<enum2$<cli::main::async_block_env$0> > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:154)
#35: tokio::runtime::runtime::Runtime::block_on<enum2$<cli::main::async_block_env$0> > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\runtime.rs:302)
#36: cli::main (C:\Users\Redfire\spiderfire\cli\src\main.rs:64)
#37: core::ops::function::FnOnce::call_once<void (*)(),tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\ops\function.rs:250)
#38: std::sys_common::backtrace::__rust_begin_short_backtrace<void (*)(),tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\sys_common\backtrace.rs:137)
#39: std::rt::lang_start::closure$0<tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\rt.rs:166)
#40: std::rt::lang_start_internal (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc/library\std\src\rt.rs:148)
#41: std::rt::lang_start<tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\rt.rs:165)
#42: main[C:\Users\Redfire\spiderfire\target\debug\cli.exe +0x33d79]
#43: __scrt_common_main_seh (D:\a\_work\1\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl:288)
#44: BaseThreadInitThunk[C:\WINDOWS\System32\KERNEL32.DLL +0x17614]
#45: RtlUserThreadStart[C:\WINDOWS\SYSTEM32\ntdll.dll +0x526a1]
```

I'm trying to figure out why destroying the runtime is failing, and I'm really not sure

[07:16:14.0667] <mccr8>
> <@redfire75369:mozilla.org> ```cpp
> Assertion failure: !IsInsideNursery(thing), at C:/Users/Redfire/.cargo/git/checkouts/mozjs-0f28a5f34a8f25e0/bb4942c/mozjs/mozjs/js/src/gc/GC.cpp:4746
> 
> #01: js::gc::ClearEdgesTracer::onEdge<JSObject> (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\GC.cpp:4746)
> #02: js::GenericTracerImpl<js::gc::ClearEdgesTracer>::onObjectEdge (C:\Users\Redfire\spiderfire\target\debug\build\mozjs_sys-277341a3d9bd2227\out\build\dist\include\js\TracingAPI.h:219)
> #03: js::gc::TraceEdgeInternal (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Tracer.h:106)
> #04: TraceExternalEdgeHelper<JSObject *> (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Marking.cpp:380)
> #05: js::gc::TraceExternalEdge (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\Marking.cpp:406)
> #06: JS::TraceEdge<JSObject *> (C:\Users\Redfire\spiderfire\target\debug\build\mozjs_sys-277341a3d9bd2227\out\build\dist\include\js\TracingAPI.h:350)
> #07: CallObjectTracer (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\jsglue.cpp:886)
> #08: mozjs::gc::trace::impl$1::trace (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:48)
> #09: mozjs::gc::trace::RootedTraceableSet::trace (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:363)
> #10: mozjs::gc::trace::trace_traceables::closure$0 (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:370)
> #11: std::thread::local::LocalKey<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet> >::try_with<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet>,mozjs::gc::trace::trace_traceables::closure_env$0,tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\thread\local.rs:446)
> #12: std::thread::local::LocalKey<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet> >::with<core::cell::RefCell<mozjs::gc::trace::RootedTraceableSet>,mozjs::gc::trace::trace_traceables::closure_env$0,tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\thread\local.rs:422)
> #13: mozjs::gc::trace::trace_traceables (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\gc\trace.rs:372)
> #14: js::gc::GCRuntime::traceEmbeddingBlackRoots (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\RootMarking.cpp:377)
> #15: js::gc::GCRuntime::finishRoots (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\gc\RootMarking.cpp:439)
> #16: JSRuntime::destroyRuntime (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\vm\Runtime.cpp:257)
> #17: js::DestroyContext (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\vm\JSContext.cpp:226)
> #18: JS_DestroyContext (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\mozjs\mozjs\js\src\jsapi.cpp:400)
> #19: mozjs::rust::impl$11::drop (C:\Users\Redfire\.cargo\git\checkouts\mozjs-0f28a5f34a8f25e0\bb4942c\rust-mozjs\src\rust.rs:419)
> #20: core::ptr::drop_in_place<mozjs::rust::Runtime> (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\ptr\mod.rs:490)
> #21: cli::evaluate::eval_module::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\evaluate.rs:100)
> #22: cli::commands::run::run::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\commands\run.rs:17)
> #23: cli::commands::handle_command::async_fn$0 (C:\Users\Redfire\spiderfire\cli\src\commands\mod.rs:49)
> #24: cli::main::async_block$0 (C:\Users\Redfire\spiderfire\cli\src\main.rs:64)
> #25: core::future::future::impl$1::poll<ref_mut$<enum2$<cli::main::async_block_env$0> > > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\future\future.rs:126)
> #26: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:541)
> #27: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:541)
> #28: tokio::runtime::scheduler::current_thread::Context::enter<enum2$<core::task::poll::Poll<tuple$<> > >,tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:350)
> #29: tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:540)
> #30: tokio::runtime::scheduler::current_thread::impl$8::enter::closure$0<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:615)
> #31: tokio::macros::scoped_tls::ScopedKey<tokio::runtime::scheduler::current_thread::Context>::set<tokio::runtime::scheduler::current_thread::Context,tokio::runtime::scheduler::current_thread::impl$8::enter::closure_env$0<tokio::runtime::scheduler::current_thr (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\macros\scoped_tls.rs:61)
> #32: tokio::runtime::scheduler::current_thread::CoreGuard::enter<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:615)
> #33: tokio::runtime::scheduler::current_thread::CoreGuard::block_on<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:530)
> #34: tokio::runtime::scheduler::current_thread::CurrentThread::block_on<enum2$<cli::main::async_block_env$0> > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\scheduler\current_thread.rs:154)
> #35: tokio::runtime::runtime::Runtime::block_on<enum2$<cli::main::async_block_env$0> > (C:\Users\Redfire\.cargo\registry\src\index.crates.io-6f17d22bba15001f\tokio-1.27.0\src\runtime\runtime.rs:302)
> #36: cli::main (C:\Users\Redfire\spiderfire\cli\src\main.rs:64)
> #37: core::ops::function::FnOnce::call_once<void (*)(),tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\core\src\ops\function.rs:250)
> #38: std::sys_common::backtrace::__rust_begin_short_backtrace<void (*)(),tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\sys_common\backtrace.rs:137)
> #39: std::rt::lang_start::closure$0<tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\rt.rs:166)
> #40: std::rt::lang_start_internal (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc/library\std\src\rt.rs:148)
> #41: std::rt::lang_start<tuple$<> > (/rustc/84c898d65adf2f39a5a98507f1fe0ce10a2b8dbc\library\std\src\rt.rs:165)
> #42: main[C:\Users\Redfire\spiderfire\target\debug\cli.exe +0x33d79]
> #43: __scrt_common_main_seh (D:\a\_work\1\s\src\vctools\crt\vcstartup\src\startup\exe_common.inl:288)
> #44: BaseThreadInitThunk[C:\WINDOWS\System32\KERNEL32.DLL +0x17614]
> #45: RtlUserThreadStart[C:\WINDOWS\SYSTEM32\ntdll.dll +0x526a1]
> ```
> 
> I'm trying to figure out why destroying the runtime is failing, and I'm really not sure

Maybe you need a minor GC before that?

[07:17:10.0819] <Redfire>
No idea what that means.

[07:18:56.0049] <jlink>
mstange: Time travel debugging? What is this world that we live in? :)
denispal : Thanks! That looks perfect.

[07:25:43.0844] <Redfire>
Actually, there's a variety of different errors I'm getting
stuff like
```
Assertion failure: kind == JS::TracerKind::Tenuring || kind == JS::TracerKind::MinorSweeping || kind == JS::TracerKind::Moving, at C:/Users/Redfire/.cargo/git/checkouts/mozjs-0f28a5f34a8f25e0/bb4942c/mozjs/mozjs/js/src/gc/Marking.cpp:158
```
and
```
Assertion failure: this->flags() == 0, at C:/Users/Redfire/.cargo/git/checkouts/mozjs-0f28a5f34a8f25e0/bb4942c/mozjs/mozjs/js/src/gc/Cell.h:790
```

[07:28:04.0308] <Redfire>
Are there supposed to be no objects traced in the heap by a global root tracing hook before the runtime is destroyed?

[07:28:29.0614] <Redfire>
 * Are there supposed to be no objects traced in the heap by a extra gc roots tracer before the runtime is destroyed?

[07:32:33.0799] <jonco>
Redfire: if you remove your extra roots tracer before destroying the runtime it should work

[07:40:46.0957] <mstange>
jlink: https://devblogs.microsoft.com/visualstudio/introducing-time-travel-debugging-for-visual-studio-enterprise-2019/

[07:48:53.0582] <jlink>
> <@mstange:mozilla.org> jlink: https://devblogs.microsoft.com/visualstudio/introducing-time-travel-debugging-for-visual-studio-enterprise-2019/

Exciting. It looks like that might be specific to code running on an Azure virtual machine. That article does mention that [something similar was introduced in WinDbg for native code](https://blogs.windows.com/windowsdeveloper/2017/09/27/time-travel-debugging-now-available-windbg-preview/) although I've never used WinDbg.

[08:02:11.0385] <mstange>
oh I see

[08:46:58.0835] <jonco>
sfink: ping

[08:56:30.0479] <wraitii>
Profiling question - I've seen https://github.com/mstange/samply get mentioned as potentially being supported as an external profiler in future versions of Spidermonkey, is there a way to use it already with ESR 102 ? I don't have an easy access to `perf` on mac OS and so as far as I know I'm stuck for better JIT profiling

[08:57:32.0950] <mstange>
wraitii: Not with ESR 102, but you can do it with 114 (the patch you need is https://bugzilla.mozilla.org/show_bug.cgi?id=1827214 )

[09:03:25.0051] <wraitii>
I see, so the ESR after 102 should support it natively. I'll try to compile trunk in the meantime, but I need to update my mac OS, don't have the 13.0 SDK '^_^

[09:03:54.0504] <mstange>
wraitii: If you use ./mach bootstrap it should download the right SDK automatically

[09:04:28.0355] <wraitii>
ah, that would be convenient. I'm building it as part of 0 A.D.'s pipeline so I'm not sure I have the bootstrap files, might need to do something in gecko-dev

[09:04:42.0977] <mstange>
oh, fun!

[09:05:26.0386] <wraitii>
> <@wraitii:mozilla.org> Hello everyone, I'm looking into Upgrading 0 A.D. from 91 to SM 102. I'm running into an odd issue. We are JS::Execute-ing some code, and I get an assertion error in `NearestEnclosingExtensibleLexicalEnvironment` that there is no env (inside a `GlobalOrEvalDeclInstantiation`). The cause, as far as I can tell, is that we `JS_DeepFreeze` a global variable. There doesn't seem to be anything else wrong or special. Any clue what might have caused this to break now?

(Self-bump on this in case someone has an idea, otherwise I think I'll end up manually deep-freezing by recursing in JS)

[09:07:09.0614] <wraitii>
> <@mstange:mozilla.org> wraitii: Not with ESR 102, but you can do it with 114 (the patch you need is https://bugzilla.mozilla.org/show_bug.cgi?id=1827214 )

Awesome news by the way, getting the ability to profile JIT code without the full gecko-profiler is something we've been terribly missing

[09:07:20.0722] <mstange>
:)

[09:10:20.0083] <Redfire>
https://paste.gg/p/redfire/8e37d68d383f429f8d393371b8a74060
Yeah this is just weird, I don't know why runtime destruction is being such a pain.

[09:40:57.0336] <wraitii>
I'm also getting compile-errors that the build scripts can't find png-config (though I have it installed via home-brew) since ESR102 on macOS, had to hardcode the path

[10:10:54.0164] <wraitii>
Got things to compile against master -> the JIT traces are properly reported as part of their flame graphs, but I'm not seeing any actual names, do I need specific flags/env settings for that ? 

[10:18:15.0756] <wraitii>
Nevermind, that's just because the latest sample release is from January mstange  ;) 

[10:18:22.0680] <wraitii>
 * Nevermind, that's just because the latest samply release is from January mstange  ;)

[10:20:22.0520] <wraitii>
oh my god this is aweoms

[10:20:26.0869] <wraitii>
 * oh my god this is awesome

[10:56:44.0577] <mgaudet>
> <@wraitii:mozilla.org> Hello everyone, I'm looking into Upgrading 0 A.D. from 91 to SM 102. I'm running into an odd issue. We are JS::Execute-ing some code, and I get an assertion error in `NearestEnclosingExtensibleLexicalEnvironment` that there is no env (inside a `GlobalOrEvalDeclInstantiation`). The cause, as far as I can tell, is that we `JS_DeepFreeze` a global variable. There doesn't seem to be anything else wrong or special. Any clue what might have caused this to break now?

Sorry you've run into this. Nothing stands out, but if you have a backtrace (or a tiny example) it likely would be a bug worth opening. 

[10:59:18.0507] <wraitii>
Mh, I can try to get a tiny example. I doubt the stack trace would help you much tbh since the crash is in code that's after the deepfreeze call

[11:02:01.0642] <wraitii>
Are there particular settings for how GCs dump jitted code in modern SM ? First thing I can tell from samply is that most of our big GCs dump all our jitted code

[11:02:08.0191] <wraitii>
(though most of it is theoretically still valid)

[11:04:25.0286] <sfink>
that's the second time this has come up in as many days :-)

[11:04:36.0506] <sfink>
we probably are overly eager to jettison jitcode

[11:05:32.0909] <sfink>
one reason is to treat jit code as roughly LRU cached. As in, the easiest way to expire old unused jit code is to expire it all and let the stuff still in use get recompiled.

[11:06:09.0976] <sfink>
at other times, it's for conservative correctness. The jit code doesn't want to have to adapt to potential or actual changes, so we just throw it all out.

[11:06:32.0982] <sfink>
there are some [heuristics](https://searchfox.org/mozilla-central/rev/8e1b221afcdae76284b1439c547b032d1f84d236/js/src/gc/GC.cpp#2247-2277) like preserving the jit code if we're animating

[11:06:46.0087] <sfink>
that's probably the closest to what you're asking for

[11:07:12.0506] <sfink>
(or rather, if we're animating then we'll still throw it out, but not as quickly)

[11:08:13.0999] <wraitii>
Think we already enable the 'setPreserveJitCode' thing. TBH the profiling suggests we're still spending most of our time in Ion, so the heuristic isn't too bad

[11:08:50.0091] <wraitii>
but we are definitely dumping code just to recompile it later in our case, and I think it might adversely affect some of the less-often-called functions (since presumably the warmup is reset every time? )

[11:09:45.0582] <sfink>
the usual feeling I've gotten when I've looked into it is that conceptually what we're doing is kind of awful, but it's hard to find cases where it is significantly hurting things

[11:10:18.0543] <sfink>
I wouldn't expect the warmup to get reset when discarding jit code during GC, but I'm not sure. jandem / iain|pto ?

[11:10:50.0207] <sfink>
but even if it isn't, the code won't get recompiled until it's actually called, so it amounts to the same thing

[11:12:24.0489] <wraitii>
hard to say from the profiling I get, could be, could be not.

[11:13:14.0745] <wraitii>
As sort of a 'hard baseline', on a main-function that we call every 'frame', we get about 10% of the time in Baseline and 90% in Ion, when it ought to be more like 98/2 since it's always the same function called always in the same way

[11:13:50.0825] <sfink>
I would expect the non-ion version to run a few times even if it starts recompiling immediately, since it won't get switched to until the compilation is complete so it'll run in the old mode (baseline, I guess?)

[11:14:05.0367] <wraitii>
Yup, that's what I'm seeing in general

[11:15:37.0584] <wraitii>
But it seems to me like the warmup counters might get reset to some extent, because some sub-functions take much longer to 'go back' to running mostly on Ion

[11:16:36.0531] <wraitii>
To be a bit more clear perhaps we have a 'Timer' function that calls a 'Resource.PerformGather' function (essentially), after each GC the 'Timer' function goes back to Ion almost instantly, but the 'Resource.PerformGather' only goes back to Ion about 50% of the way to the next GC

[11:16:53.0172] <wraitii>
so we're wasting 50% of the time in baseline for no seeming reason, since it's the same function with basically the same parameters

[11:17:23.0028] <sfink>
given that you're already using the `setPreserveJitCode` thing, I think you'll need to consult an actual jit person

[11:17:56.0947] <sfink>
I don't know when such a person will be online

[11:18:23.0488] <wraitii>
no worries, and I can upload some profile runs if there's interest. It's just my first time finally looking at this kind of data and there's some fairly obvious patterns :D

[11:19:12.0331] <sfink>
I'm curious, and I'd also like to know how similar what you're seeing is to what we typically see with Firefox

[11:20:49.0180] <wraitii>
Should I open a bug ?

[11:22:13.0534] <sfink>
sure, it seems like it would be a good place to collect information

[11:58:39.0768] <wraitii>
Opened https://bugzilla.mozilla.org/show_bug.cgi?id=1834848 and attached a small profiling replay which showcases the above behaviour

[12:27:52.0932] <wraitii>
Is it correct that we don't need to AutoRealm in C++ if we know that we are being called from a JS function ? 

[12:34:54.0944] <sfink>
yes, you only need to use it if you're going to be working with an object that may be from another Realm, and the work you're doing could have actions or side effects that need to happen within that Realm (eg JS function calls). Ordinarily you can just unwrap any cross-realm data and work with it.

[12:36:47.0296] <sfink>
or you can use `CallNonGenericMethod` which will do 90% of the right thing, and 10% the guaranteed-to-be-wrong thing (which mainly just shows up as thrown Errors being in the wrong Realm.) But anyway, that's still only relevant if your function needs to call something else.

[12:37:37.0433] <sfink>
the above is my understanding, at least

[12:37:53.0775] <wraitii>
I think in general we're not doing any cross-realm calls in our general code

[12:38:01.0317] <wraitii>
but we do have AutoRealm wrappers everywhere

[12:38:08.0214] <wraitii>
and they end up showing in the profiling in some places

[12:38:29.0916] <wraitii>
I think I might get on a mission to purge some of the un-necessary ones, which are probably 'most'

[12:38:49.0715] <sfink>
you need to get into your global's Realm somewhere, but that can probably be very early on

[12:39:06.0262] <wraitii>
But if the stack is C++ -> JS -> C++

[12:39:14.0376] <wraitii>
does the latter C++ code need to "re-realm"

[12:39:19.0334] <sfink>
no

[12:39:28.0395] <wraitii>
'cause I think that's most of the calls we do

[12:39:36.0657] <sfink>
seems likely

[12:40:18.0882] <wraitii>
good to know, thanks

[12:40:37.0703] <wraitii>
I'll be around in the coming days if the GC-people want some more details on the profiling / have questions / anything

[12:40:49.0833] <wraitii>
thanks again for enabling JIT-profiling without gecko :) 


2023-05-25
[17:45:35.0481] <iain|pto>
> <@sfink:mozilla.org> I wouldn't expect the warmup to get reset when discarding jit code during GC, but I'm not sure. jandem / iain|pto ?

[We do reset it.](https://searchfox.org/mozilla-central/source/js/src/vm/JSScript-inl.h#236)

[05:16:42.0304] <Redfire>
> <@redfire75369:mozilla.org> https://paste.gg/p/redfire/8e37d68d383f429f8d393371b8a74060
> Yeah this is just weird, I don't know why runtime destruction is being such a pain.

small bump on this one, I'm not sure why it's complaining as such.

[05:37:06.0495] <jandem>
Redfire: looks like the GC has something in its store buffer that's now invalid

[05:37:27.0715] <jandem>
maybe you're freeing some data without notifying the GC?

[05:39:38.0325] <Redfire>
Don't think so, I can't seem to find any such thing

[05:45:59.0546] <Redfire>
Problematic method seems to be `ReadableStreamDefaultReader.prototype.read`

[05:46:16.0012] <Redfire>
 * Problematic method seems to be `ReadableStreamDefaultReader.prototype.read`
Without calling that, nothing weird happens.

[05:48:13.0369] <jonco>
Redfire: can you use rr to find out what the problematic CellPtrEdge::edge points to?

[05:48:56.0306] <Redfire>
On Windows, not Linux. and I couldn't figure out how WinDbg works (used to debugging in CLion)

[05:52:35.0707] <jonco>
It looks like the destructor is not being run for something holding GCable JS data

[05:54:06.0348] <Redfire>
Normally I'd be blaming my tracing, but in this case, those never actually fire, which is confusing me.

[06:02:30.0666] <Redfire>
Destructors seem to not be run on any of my 3 structs, each of which holds a lot of objects/values on the heap

[06:02:53.0591] <Redfire>
I've pretty much left that up to the finalise operation

[06:08:43.0504] <jandem>
Redfire: what if you trigger a GC at an earlier point? maybe you can narrow it down a bit more this way

[06:10:00.0981] <Redfire>
using what, `JS_GC`?

[06:11:25.0055] <jandem>
that should work

[06:13:20.0166] <Redfire>
What gc reason should I be passing in, or does that not matter

[06:14:23.0696] <jandem>
`JS::GCReason::API` or something, but for this it doesn't really matter

[06:19:56.0883] <Redfire>
```rs
let promise = Promise::new(cx);
			match stream.state {
				State::Readable => stream.controller.pull(cx, &promise)?,
				State::Closed => unsafe {
					let request = ReadResult { value: None, done: true };
					promise.resolve(cx, &request.as_value(cx));
				},
				State::Errored => {
					promise.reject(
						cx,
						&stream
							.error
							.as_ref()
							.map(|error| Value::from(unsafe { Local::from_raw_handle(error.handle()) }))
							.unwrap_or_else(|| Value::undefined(cx)),
					);
				}
			}
			unsafe { mozjs::jsapi::JS_GC(**cx, mozjs::jsapi::GCReason::API); }
```
this bit of code here has the assertion trip

[06:20:28.0542] <Redfire>
 * ```rs
            let promise = Promise::new(cx);
			match stream.state {
				State::Readable => stream.controller.pull(cx, &promise)?,
				State::Closed => unsafe {
					let request = ReadResult { value: None, done: true };
					promise.resolve(cx, &request.as_value(cx));
				},
				State::Errored => {
					promise.reject(
						cx,
						&stream
							.error
							.as_ref()
							.map(|error| Value::from(unsafe { Local::from_raw_handle(error.handle()) }))
							.unwrap_or_else(|| Value::undefined(cx)),
					);
				}
			}
			unsafe { mozjs::jsapi::JS_GC(**cx, mozjs::jsapi::GCReason::API); }
```

this bit of code here has the assertion trip

[06:20:35.0377] <Redfire>
 * ```rs
                        let promise = Promise::new(cx);
			match stream.state {
				State::Readable => stream.controller.pull(cx, &promise)?,
				State::Closed => unsafe {
					let request = ReadResult { value: None, done: true };
					promise.resolve(cx, &request.as_value(cx));
				},
				State::Errored => {
					promise.reject(
						cx,
						&stream
							.error
							.as_ref()
							.map(|error| Value::from(unsafe { Local::from_raw_handle(error.handle()) }))
							.unwrap_or_else(|| Value::undefined(cx)),
					);
				}
			}
			unsafe { mozjs::jsapi::JS_GC(**cx, mozjs::jsapi::GCReason::API); }
```

this bit of code here has the assertion trip

[06:22:40.0604] <Redfire>
A `JS_GC` before this code block doesn't trip it, so something in here is involved

[06:22:58.0485] <Redfire>
 * A `JS_GC` before this code block doesn't trip it, so something in here is involved
I know for a fact it uses the `State::Readable` codepath

[06:30:20.0710] <Redfire>
Oh I'm absolutely stupid

[06:31:31.0924] <Redfire>
```rs
if let Some((chunk, _)) = controller.queue.pop_front() {
					unsafe { mozjs::jsapi::JS_GC(**cx, mozjs::jsapi::GCReason::API); }
					if controller.close_requested && controller.queue.is_empty() {
						controller.pull = None;
						controller.cancel = None;
						controller.size = None;

						stream.close(cx)?;
					} else {
						controller.pull_if_needed(cx)?;
						unsafe { mozjs::jsapi::JS_GC(**cx, mozjs::jsapi::GCReason::API); }
					}
					println!("Read Result To Value");
					let result = ReadResult { value: Some(chunk.get()), done: true };
					promise.resolve(cx, unsafe { &result.as_value(cx) });
					unsafe { mozjs::jsapi::JS_GC(**cx, mozjs::jsapi::GCReason::API); }
					Ok(())
				}
```
`ReadResult::as_value` creates a new object with `chunk` and `done`. However, in here, the `Heap` for `chunk` gets dropped so it can't be referred to anymore.

[06:32:42.0085] <Redfire>
The one time I try and optimise something without rooting it, I mess up.

[06:33:19.0111] <jandem>
it's nice how the bug was in the `unsafe` block :)

[06:34:22.0494] <jandem>
or maybe it was the code outside it?

[06:37:15.0059] <Redfire>
wait no, that's not even the right codepath

[06:37:34.0190] <Redfire>
the queue is empty, that can't be it ðŸ¤¦

[06:38:01.0059] <jandem>
ah

[06:46:06.0461] <Redfire>
The entire problem seems to be... this?
```rs
reader.requests.push_back(*Heap::boxed(***promise));
```
me storing the promises on the heap

[06:46:17.0949] <Redfire>
 * The entire problem seems to be... this?

```rs
reader.requests.push_back(*Heap::boxed(***promise));
```

me storing the promises on the heap and then when trying to trace them, it fails

[07:04:12.0992] <Redfire>
At this point, that promise is literally just a rooted `NewPromiseObject(cx, HandleObject::null())`

[07:30:20.0741] <jandem>
Redfire: maybe missing destructors when resizing the `requests` list/vector?

[07:35:40.0340] <Redfire>
The only resizing is pushing the one promise in, and the trace is running on it

[07:36:33.0654] <Redfire>
https://paste.gg/p/redfire/b113713b759d416a809f4712182568a9

[07:37:27.0407] <jandem>
Redfire: but does pushing that promise resize/move the underlying memory?

[08:00:12.0941] <Redfire>
That could certainly explain it, lemme see if fixing that fixes it

[08:01:03.0517] <Redfire>
in theory I could get post a barrier too, right?  (not doing that, but good to know)

[08:04:20.0230] <Redfire>
So it fixed the assertion and resulted in a segfault, just great

[08:04:51.0160] <jandem>
where is the segfault?

[08:05:24.0547] <Redfire>
```rs
mozjs::rust::get_object_group(*mut mozjs_sys::generated::root::JSObject) rust.rs:800
mozjs::rust::get_object_realm(*mut mozjs_sys::generated::root::JSObject) rust.rs:810
mozjs::rust::maybe_wrap_object_value(*mut mozjs_sys::generated::root::JSContext,mozjs::gc::root::MutableHandle<mozjs_sys::generated::root::JS::Value>) rust.rs:848
mozjs::rust::maybe_wrap_object_or_null_value(*mut mozjs_sys::generated::root::JSContext,mozjs::gc::root::MutableHandle<mozjs_sys::generated::root::JS::Value>) rust.rs:859
ion::conversions::value::to::impl$6::to_value(*mut *mut mozjs_sys::generated::root::JSObject,*mut ion::context::Context,*mut ion::value::Value) to.rs:115
ion::conversions::value::to::ToValue::as_value<ptr_mut$<mozjs_sys::generated::root::JSObject> >(*mut *mut mozjs_sys::generated::root::JSObject,*mut ion::context::Context) to.rs:25
enum2$<runtime::event_loop::microtasks::Microtask>::run(*mut ion::context::Context) microtasks.rs:38
runtime::event_loop::microtasks::MicrotaskQueue::run_jobs(*mut ion::context::Context) microtasks.rs:75
runtime::event_loop::EventLoop::poll_event_loop(*mut ion::context::Context,*mut core::task::wake::Context) mod.rs:61
runtime::event_loop::impl$0::run_event_loop::async_fn$0::closure$0(*mut runtime::event_loop::impl$0::run_event_loop::async_fn$0::closure_env$0,*mut core::task::wake::Context) mod.rs:45
futures_util::future::poll_fn::impl$2::poll<enum2$<core::result::Result<tuple$<>,enum2$<core::option::Option<ion::exception::ErrorReport> > > >,runtime::event_loop::impl$0::run_event_loop::async_fn$0::closure_env$0>(core::pin::Pin<ref_mut$<futures_util::future::poll_fn::PollFn<runtime::event_loop::impl$0::run_event_loop::async_fn$0::closure_env$0> > >,*mut core::task::wake::Context) poll_fn.rs:56
runtime::event_loop::impl$0::run_event_loop::async_fn$0(core::pin::Pin<ref_mut$<enum2$<runtime::event_loop::impl$0::run_event_loop::async_fn_env$0> > >,*mut core::task::wake::Context) mod.rs:45
runtime::runtime::impl$0::run_event_loop::async_fn$0(core::pin::Pin<ref_mut$<enum2$<runtime::runtime::impl$0::run_event_loop::async_fn_env$0> > >,*mut core::task::wake::Context) runtime.rs:46
cli::evaluate::run_event_loop::async_fn$0(core::pin::Pin<ref_mut$<enum2$<cli::evaluate::run_event_loop::async_fn_env$0> > >,*mut core::task::wake::Context) evaluate.rs:121
cli::evaluate::eval_module::async_fn$0(core::pin::Pin<ref_mut$<enum2$<cli::evaluate::eval_module::async_fn_env$0> > >,*mut core::task::wake::Context) evaluate.rs:98
cli::commands::run::run::async_fn$0(core::pin::Pin<ref_mut$<enum2$<cli::commands::run::run::async_fn_env$0> > >,*mut core::task::wake::Context) run.rs:17
cli::commands::handle_command::async_fn$0(core::pin::Pin<ref_mut$<enum2$<cli::commands::handle_command::async_fn_env$0> > >,*mut core::task::wake::Context) mod.rs:49
cli::main::async_block$0(core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > >,*mut core::task::wake::Context) main.rs:64
core::future::future::impl$1::poll<ref_mut$<enum2$<cli::main::async_block_env$0> > >(core::pin::Pin<ref_mut$<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > >,*mut core::task::wake::Context) future.rs:125
tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >(tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >) current_thread.rs:541
[Inlined] tokio::runtime::coop::with_budget(tokio::runtime::coop::Budget,tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >) coop.rs:107
[Inlined] tokio::runtime::coop::budget(tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >) coop.rs:73
tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >(tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >) current_thread.rs:541
tokio::runtime::scheduler::current_thread::Context::enter<enum2$<core::task::poll::Poll<tuple$<> > >,tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > > >(*mut tokio::runtime::scheduler::current_thread::Core,tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >) current_thread.rs:350
tokio::runtime::scheduler::current_thread::impl$8::block_on::closure$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >(tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,*mut tokio::runtime::scheduler::current_thread::Core,*mut tokio::runtime::scheduler::current_thread::Context) current_thread.rs:540
tokio::runtime::scheduler::current_thread::impl$8::enter::closure$0<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > >(tokio::runtime::scheduler::current_thread::impl$8::enter::closure_env$0<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > >) current_thread.rs:615
tokio::macros::scoped_tls::ScopedKey<tokio::runtime::scheduler::current_thread::Context>::set<tokio::runtime::scheduler::current_thread::Context,tokio::runtime::scheduler::current_thread::impl$8::enter::closure_env$0<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > >,tuple$<alloc::boxed::Box<tokio::runtime::scheduler::current_thread::Core,alloc::alloc::Global>,enum2$<core::option::Option<tuple$<> > > > >(*mut tokio::runtime::scheduler::current_thread::Context,tokio::runtime::scheduler::current_thread::impl$8::enter::closure_env$0<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > >) scoped_tls.rs:61
tokio::runtime::scheduler::current_thread::CoreGuard::enter<tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >,enum2$<core::option::Option<tuple$<> > > >(tokio::runtime::scheduler::current_thread::CoreGuard,tokio::runtime::scheduler::current_thread::impl$8::block_on::closure_env$0<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >) current_thread.rs:615
tokio::runtime::scheduler::current_thread::CoreGuard::block_on<core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > > >(tokio::runtime::scheduler::current_thread::CoreGuard,core::pin::Pin<ref_mut$<enum2$<cli::main::async_block_env$0> > >,*mut core::panic::location::Location) current_thread.rs:530
tokio::runtime::scheduler::current_thread::CurrentThread::block_on<enum2$<cli::main::async_block_env$0> >(*mut enum2$<tokio::runtime::scheduler::Handle>,enum2$<cli::main::async_block_env$0>,*mut core::panic::location::Location) current_thread.rs:154
tokio::runtime::runtime::Runtime::block_on<enum2$<cli::main::async_block_env$0> >(enum2$<cli::main::async_block_env$0>,*mut core::panic::location::Location) runtime.rs:302
cli::main() main.rs:64
core::ops::function::FnOnce::call_once<void (*)(),tuple$<> >(*mut ) function.rs:250
[Inlined] core::hint::black_box(tuple$<>) hint.rs:296
std::rt::lang_start::closure$0<tuple$<> >(*mut std::rt::lang_start::closure_env$0<tuple$<> >) rt.rs:166
[Inlined] core::ops::function::impls::impl$2::call_once() function.rs:287
[Inlined] std::panicking::try::do_call() panicking.rs:487
[Inlined] std::panicking::try() panicking.rs:451
[Inlined] std::panic::catch_unwind() panic.rs:140
[Inlined] std::rt::lang_start_internal::closure$2() rt.rs:148
[Inlined] std::panicking::try::do_call() panicking.rs:487
[Inlined] std::panicking::try() panicking.rs:451
[Inlined] std::panic::catch_unwind() panic.rs:140
std::rt::lang_start_internal() rt.rs:148
std::rt::lang_start<tuple$<> >(*mut ,i64,*mut *mut u8,u8) rt.rs:165
main 0x00007ff75e483d79
[Inlined] invoke_main() 0x00007ff760cb2bdc
__scrt_common_main_seh() 0x00007ff760cb2bba
<unknown> 0x00007ff8a7d87614
<unknown> 0x00007ff8a96226a1
```
within rust, unfortunately

[08:09:32.0064] <Redfire>
Ok, apparently that was a bug on my side, errr

[08:09:38.0905] <Redfire>
Seems to work now!
Thanks for all the help

[08:10:03.0458] <Redfire>
I'll take very much note not to move heap values unnecessarily (and heed the warning on the `Heap::boxed` constructor)

[10:51:48.0616] <wraitii>
I'm interested if there are some ways for me to hack into the SM codebase and test out whether dumping / not dumping the JIT code + warmup counters so often for 0 A.D. has positive performance implications. I tried a few things but they didn't really seem to work out too well. Doesn't have to be robust.

[12:18:59.0472] <mgaudet>
> <@wraitii:mozilla.org> I'm interested if there are some ways for me to hack into the SM codebase and test out whether dumping / not dumping the JIT code + warmup counters so often for 0 A.D. has positive performance implications. I tried a few things but they didn't really seem to work out too well. Doesn't have to be robust.

So, if you can hack 0AD to be able to access our shell testing functions `gcPreserveCode()` seems to do what you want: https://searchfox.org/mozilla-central/source/js/src/builtin/TestingFunctions.cpp#8889-8891

[12:19:39.0481] <mgaudet>
If you can't, but you can somehow hack the runtime to set [this flag](https://searchfox.org/mozilla-central/source/js/src/gc/GCRuntime.h#436), it should work the same

[12:20:16.0953] <mgaudet>
Oh! Or actually, this is part of the public API https://searchfox.org/mozilla-central/source/js/public/RealmOptions.h#117 

[12:20:23.0939] <mgaudet>
Should also work

[14:03:22.0344] <Tim>
mgaudet: Thanks for isolating the bug with the change-array-by-copy patch. I updated the PR and am currently running a `perf` try build ( https://treeherder.mozilla.org/jobs?repo=try&revision=9c7c877228e6026f3db7a71641caa858bc3f61f0 ). Hopefully that runs the right tests

[14:23:36.0550] <mgaudet>
Tim: Cool. I suspect we'd be fine to land it again, but if you'd like I can wait till tomorrow. 

I've had my own issue with `./mach try auto` recently 

[14:23:49.0892] <Tim>
> <@mgaudet:mozilla.org> Tim: Cool. I suspect we'd be fine to land it again, but if you'd like I can wait till tomorrow. 
> 
> I've had my own issue with `./mach try auto` recently

up to you

[14:24:24.0076] <mgaudet>
I'll hit the button.... YOLO. 


2023-05-26
[01:22:37.0796] <wraitii>
> <@mgaudet:mozilla.org> Oh! Or actually, this is part of the public API https://searchfox.org/mozilla-central/source/js/public/RealmOptions.h#117

Mh, I believe we are setting this flag, yet the JIT code still gets removed. I'll try hacking up the runtime itself (I'm compiling manually, so I can chance anything)

[07:43:49.0565] <davidj361>
I'm a bit confused for `JS_ParseJSON` does it not create a JS Object from the given JSON and put it onto a global to access? I don't see any mention of global for it.

[07:44:23.0412] <davidj361>
 * I'm a bit confused for `JS_ParseJSON`. Does it not create a JS Object from the given JSON and put it onto a global to access? I don't see any mention of global for it.

[07:45:12.0479] <Ms2ger>
No

[07:45:19.0002] <Ms2ger>
It returns the object

[07:45:45.0886] <davidj361>
ah right, you give it an already rooted object. my fault

[08:28:29.0739] <jonco>
Is there a way to tell the compiler that a value is non-null?  I seem to remember something like MOZ_UNREACHABLE but I can't find it now

[08:29:02.0307] <mstange>
jonco: MOZ_MAKE_COMPILER_ASSUME_IS_UNREACHABLE

[08:30:42.0017] <jonco>
aha, thanks

[08:37:01.0143] <padenot>
also https://searchfox.org/mozilla-central/source/mfbt/NotNull.h

[08:37:20.0408] <padenot>
but it's not the same

[09:45:59.0339] <wraitii>
Mystery of the 0 A.D. bit code being dumped solved -> it is when we are running shrinking GCs

[09:46:13.0668] <wraitii>
which is part of the API I think, so al lclear

[09:46:42.0540] <mgaudet>
Hey cool :) Glad that got figured out. 

[10:13:18.0957] <wraitii>
Is there a doc of the IR somewhere ? 

[10:13:30.0821] <wraitii>
I'm wondering what 'MoveGroup' means for example

[10:25:26.0909] <cassio.neri>
Hi all. My patch failed a wpt test and has been backed out. I have a fix which I expect to be reviewed again (by anba, preferably.) I haven't pulled and updated since I've submitted the problematic patch and thus, my tip is the revision that I've submitted. In particular, I don't have the backout revision. Could I fix locally (on top of my tip) and then run:

hg commit --amend
moz-phab

Or should I, say, pull/update and do something else?


[10:31:33.0195] <mgaudet>
cassio.neri: That would definitely work; because phabricator/lando work on patches, so long as you patch would apply cleanly on autoland's tip, it's fine if local history doesn't match remote. 

[10:32:01.0321] <mgaudet>
if you wanted to, you could also rebase your code manually (`hg pull --rebase central` or `hg rebase -s . -d central` ) 

[12:40:55.0633] <cassio.neri>
mgaudet: Thanks.


2023-05-27
[17:59:08.0633] <iain|pto>
wraitii: There is no documentation of the IR. MoveGroup represents a set of register moves that need to be done at that point according to the register allocator. See [here](https://searchfox.org/mozilla-central/source/js/src/jit/BacktrackingAllocator.cpp#131)

[17:59:47.0315] <iain|pto>
 * wraitii: There is no up-to-date documentation of MIR/LIR. MoveGroup represents a set of register moves that need to be done at that point according to the register allocator. See [here](https://searchfox.org/mozilla-central/source/js/src/jit/BacktrackingAllocator.cpp#131)

[00:40:25.0971] <wraitii>
> <@iain:mozilla.org> wraitii: There is no up-to-date documentation of MIR/LIR. MoveGroup represents a set of register moves that need to be done at that point according to the register allocator. See [here](https://searchfox.org/mozilla-central/source/js/src/jit/BacktrackingAllocator.cpp#131)

I seem to have these after CallNative instructions a fair bit, should I then assume that those MoveGroups would be removed if the native call was removed ? 

[09:39:34.0191] <wraitii>
Is there a faster way to init large typed arrays (e.g. uint8Array) with some constant value? We currently use .fill() but that seems rather slow.
Furthermore, profiling with samply / IONPERF, SM emits an InterruptCheck in the loop head, and this ends up just trashing the memory cache, as the inner loop is very very short

[10:04:27.0408] <wraitii>
(to be honest there's a non-zero chance that doing it in C++ explicitly would be good)


2023-05-28
[06:19:43.0022] <wraitii>
Ok the reason why MoveGroup seems to show up after CallNative in the JIT is the Spectre mitigations, it seems.
Is there any particular reason why turning JSJITCOMPILER_SPECTRE_JIT_TO_CXX_CALLS off for 0 A.D. would be dangerous? It's a solid 10-15% speed improvement in some benchmarks

[06:20:25.0563] <wraitii>
(on ARM M1 anyways)

[08:21:14.0208] <iain>
wraitii: The spectre mitigations are only useful if you are running arbitrary untrusted JS code in the same process as sensitive data. 0 A.D. probably doesn't need them.

[09:08:14.0811] <wraitii>
By the way I found an 'edge case' for Map object iteration -> doing for (let [key, value] of someMap) 

[09:08:41.0742] <wraitii>
 * By the way I found an 'edge case' for Map object iteration -> doing `for (let \[key, value\] of someMap)` is slower than `someMap.forEach((key, value) => ...)` by a substantial amount, because the iterator-version actually creates the array

[09:08:53.0953] <wraitii>
not sure if that's something you can easily fix

[09:14:10.0615] <wraitii>
 * By the way I found an 'edge case' for Map object iteration -> doing `for (let \[key, value\] of someMap)` is slower than `someMap.forEach((key, value) => ...)` by a substantial amount, because the iterator-version actually creates the array (despite it being instantly restructured)

[09:14:13.0709] <wraitii>
 * By the way I found an 'edge case' for Map object iteration -> doing `for (let \[key, value\] of someMap)` is slower than `someMap.forEach((key, value) => ...)` by a substantial amount, because the iterator-version actually creates the array (despite it being instantly destructured)

[09:29:48.0033] <iain>
It can probably be done, but it would be a non-trivial amount of work, and map iteration is not hot enough for us to have spent time on it


2023-05-29
[00:22:19.0475] <arai>
Any opinion about adding dedicate type for UTF-8-encoded `UniqueChars` ?  I'm preparing a patch for [bug 1831845](https://bugzilla.mozilla.org/show_bug.cgi?id=1831845) and there are some case that filename is stored in `UniqueChars`, and wondering if worth adding dedicate type for UTF-8

[00:22:22.0200] <botzilla>
https://bugzil.la/1831845 â€” NEW (nobody) â€” Use UTF-8-specific type for filename/path which contains UTF-8

[00:25:47.0075] <arai>
so far I'm replacing `const char*` fields with `JS::ConstUTF8CharsZ`

[04:45:25.0596] <smag>
Hi - I'm hoping someone can point me in the right direction - I'm trying to get localisation working for Date() and nothing seems to be working. It seems like Intl isn't available at all and toLocaleString keeps returning GMT.

[04:45:42.0680] <smag>
Currently testing in the WASI demo

[04:50:09.0344] <smag>
I'm new to spider monkey so if it's a novice question I do apologise :) 

[05:34:29.0433] <wraitii>
Am I generally correct in saying that to pass (sufficiently largeâ„¢) data from C++ to JS, it might be faster to create an ArrayBuffer, pass that to JS, and do the object construction in (jitted) JS, than to manually do the object construction in C++ ?
Creating a JS array from C++ manually is relatively slow, because the APIs go through a lot of hoops as they don't 'know' that the underlying object is an array

[05:34:45.0549] <wraitii>
 * Am I generally correct in saying that to pass (sufficiently largeâ„¢) data from C++ to JS, it might be faster to create an ArrayBuffer, pass that to JS, and do the object construction in (jitted) JS, than to manually do the object construction in C++ ?
Creating a JS array from C++ manually is relatively slow, because the APIs go through a lot of hoops as they don't 'know' that the underlying object is an array.

[05:35:22.0543] <wraitii>
We also often create simple objects with a known layout, and SetProperty is relatively slow as it adds new undefined properties to  plain object. it seems like passing the raw-data and jit-parsing that might be a faster option

[06:07:38.0844] <arai>
smag: you're using https://mozilla-spidermonkey.github.io/sm-wasi-demo/ ? localization is disabled there (`--without-intl-api` in https://searchfox.org/mozilla-central/source/js/src/devtools/automation/variants/wasi#2)

[06:15:39.0912] <arai>
if it's not necessarily be in WASI demo, you can build your own SpiderMonkey JS shell locally and test there https://firefox-source-docs.mozilla.org/js/build.html

[07:18:27.0696] <wraitii>
> <@wraitii:mozilla.org> Am I generally correct in saying that to pass (sufficiently largeâ„¢) data from C++ to JS, it might be faster to create an ArrayBuffer, pass that to JS, and do the object construction in (jitted) JS, than to manually do the object construction in C++ ?
> Creating a JS array from C++ manually is relatively slow, because the APIs go through a lot of hoops as they don't 'know' that the underlying object is an array.

Answering my own question -> the theory holds water, unfortunately creating an ArrayBufferFromUserContents and a DataView on that seems rather slow itself

[07:18:38.0090] <wraitii>
so this is unlikely to be worth doing for small enough items

[07:22:27.0727] <wraitii>
(the main cost seems to be micro-gcs in the nursery, but also some raw js overhead)

[15:07:25.0397] <smag>
> <@arai:mozilla.org> smag: you're using https://mozilla-spidermonkey.github.io/sm-wasi-demo/ ? localization is disabled there (`--without-intl-api` in https://searchfox.org/mozilla-central/source/js/src/devtools/automation/variants/wasi#2)

Thank you! I thought i was going crazy :)


2023-05-30
[22:13:02.0535] <ptomato>
is the advice in https://github.com/mozilla-spidermonkey/spidermonkey-embedding-examples/blob/esr102/examples/cookbook.cpp#L341-L375 for throwing a new Error object still current?

[22:13:26.0040] <ptomato>
or should we be using `JS::CreateError()` and `JS::SetPendingExceptionStack()` these days?

[00:04:56.0294] <jandem|away>
ptomato: `JS::CreateError` seems nicer than that `JS_CallFunctionName`. Note that `JS_SetPendingException` has an optional argument that specifies whether it should capture a stack, so that part should be fine

[00:15:29.0573] <wraitii>
Random suggestion: would it be workable at all to treat PersistentRooted specially when tracing the nursery (by .e.g pretenuring anything owned by a PersistentRooted, so that you don't even need to trace it).
0 A.D. uses a lot of PersistentRooted objects for the JS wrappers of our C++ components. These are traced when clearing the nursery, which is generally a waste of time (those objects live much longer).
Or is that something that the API can already do in another way and we should change our logic ? 

[00:18:05.0517] <wraitii>
I see that roots added via JS_AddExtraGCRootsTracer aren't traced in minor GCs, but I don't understand the comment saying why (though conceptually that API doesn't say it's dangerous so that's probably safe)

[00:27:12.0912] <wraitii>
> <@wraitii:mozilla.org> I see that roots added via JS_AddExtraGCRootsTracer aren't traced in minor GCs, but I don't understand the comment saying why (though conceptually that API doesn't say it's dangerous so that's probably safe)

K think I can answer my own question -> storing something in a Heap puts a reference to it (or something) in the store buffer, which means it won't be GCed even if the object is in the nursery. Ergo, safe.

[00:28:00.0081] <wraitii>
Conclusion is that I should probably change our code from persistentrooted to JS_AddExtraGCRootsTracer so that nursery collecting becomes faster

[00:28:15.0988] <wraitii>
which ultimately might also make it possible for us to use a larger nursery and reduce our GC time, would need to test that though

[01:36:22.0078] <jandem>
approximately how many persistent roots are we talking about? there are probably better ways to represent this

[01:47:41.0499] <wraitii>
Several thousands

[01:47:49.0905] <wraitii>
 * Several thousands potentially

[01:48:09.0899] <wraitii>
 * Several thousands potentially, each entities have several, and we can have thousands of these

[01:48:53.0489] <wraitii>
It seems like it'd be much more efficient to register a `JS_AddExtraGCRootsTracer` in the central 'component manager' C++ struct we have, and iterate manually over our JS components (which would use JS::Heap instead)

[02:20:46.0416] <jonco>
PersistentRooted is not the most efficient way to trace roots and is meant for use for convenience of adding a few roots or when nothing else will work.  Adding your own tracer that understands your data structures will be more efficient.

[02:21:51.0108] <jonco>
Yes, use of Heap<> will add store buffer entries which will trace nursery GC things automatically if they are referened from the heap.

[02:22:00.0418] <jonco>
 * Yes, use of Heap\<> will add store buffer entries which will trace nursery GC things automatically if they are referenced from the heap.

[02:24:28.0758] <wraitii>
I think the reason we did it is mostly convenience, and we don't technically keep a list of all JS-component-objects, because we had some lazy/on-demand initialisation, but I think overall just doing our own thing will still probably be faster (since adding new roots requires them to be added/pruned from the list anyways)

[02:27:04.0686] <wraitii>
I had noticed that doing that was slow-ish in itself, but I hadn't noticed that it led to a bad pattern in the nursery too, which seems worse

[04:50:29.0401] <Redfire>
Funny thing is servo mozjs is pretty much planning to only have `JS_AddExtraGCRootsTracer` (in the process of being merged)
The glue needed for PersistentRooted is really annoying.

[04:55:00.0102] <wraitii>
changing them is probably a good idea regardless wrt to performance. 

[04:55:32.0702] <Redfire>
Servo itself only uses the former.

[04:57:19.0814] <Redfire>
 * Servo itself only uses the former. (See [script_runtime.rs](https://github.com/servo/servo/blob/fc07c2127669ecd6c2419552553212a0cd333ea3/components/script/script_runtime.rs#L475))

[05:40:32.0425] <wraitii>
I'm trying to figure out if we actually need to run shrinking gcs manually, but it seems like the answer is 'no'.
As far as I can tell, the main positive impact for 0 A.D. would be that the cells get 'defragmented', so that the total # of arenas is reduced. But we don't actually 'gain' any memory capability, as the arenas otherwise have free slots. The only situation, insofar as I can tell, where there would be a relevant difference is if we needed  to allocate a 'big' object and that wasn't possible in any of the remaining arenas, where a compacted-version might allow it. But that seems rather unlikely to me, as in general the size of objects seems to be very similar and rather small.

[05:40:57.0190] <wraitii>
Furthermore, shrinking GCs frees memory, that we might then re-allocate if the runtime grows. So that seems less efficient than running partially empty arenas, potentially

[08:12:50.0033] <mgaudet>
i.ain: Great analysis in https://bugzilla.mozilla.org/show_bug.cgi?id=1833315. As far as action goes, I'm not sure we have much in the way of options... perhaps on android (and android only) we mark js::StackUses as MOZ_NEVER_INLINE?; while this appears solidly to be a hardware bug it has to be something about the instruction -sequence- otherwise we'd see waaaaaay more crashes of this nature I think. So perhaps judicious use of `MOZ_NEVER_INLINE` might jostle emitted instructions just enough that we can get this to work properly? 


[08:13:11.0274] <mgaudet>
Or perhaps we should see if someone from the tools team can suggest a more precise intervention?

[09:07:06.0773] <iain>
mgaudet: The part that stands out to me is that we're storing the opcode, and then reading it back to look it up in the table instead of just using the value we already have. I haven't quite worked out where that happens, and it's a little weird that the compiler doesn't fix it for us, but if we could generate better code there then the problem would go away.

[09:08:10.0598] <mgaudet>
iain: That's js::StackUses -- which is slightly awkward, because you wish you could just carry the op along, but because there are sometimes secondary data needed from the instruction stream, passing `jsbytecode*` makes more sense in the general case. 

[09:08:34.0465] <mgaudet>
https://searchfox.org/mozilla-central/source/js/src/vm/BytecodeUtil.h#331,341,345,352

[09:08:39.0800] <iain>
Ah, so it is

[09:08:40.0931] <sfink>
There aren't any truly big objects. Anything big will get a small thing allocated in the arena that points to the big stuff in malloc memory. There [aren't that many](https://searchfox.org/mozilla-central/source/js/src/gc/AllocKind.h#60-79) different kinds of objects that will get allocated, and the largest has space for 16 64-bit Values.

[09:09:44.0797] <sfink>
Also, since the tenured heap tracks free space within the arenas (and everything stored in an arena is the same size), you're right that compaction won't help if you're just going to end up allocating enough to use up the fragmented space in the partially-filled arenas.

[09:10:42.0384] <sfink>
It'll only save memory if you have a bunch of partially filled arenas and can compact them down to fewer, and you've mostly stopped allocating stuff so you won't be filling them back up agian.

[09:11:49.0695] <sfink>
I suspect it should mostly happen only when things have been idle for a while and will be idle for a while longer. Which may never happen in your game?

[09:15:01.0019] <ptomato>
> <@jandem:mozilla.org> ptomato: `JS::CreateError` seems nicer than that `JS_CallFunctionName`. Note that `JS_SetPendingException` has an optional argument that specifies whether it should capture a stack, so that part should be fine

thanks! by the way, what's the reason we have both `JS_SetPendingException` and `JS::SetPendingExceptionStack`? I thought the latter might be for when you need to customize the stack, but you can also provide a custom stack to `JS::CreateError`.

[09:15:21.0984] <sfink>
`ArrayBufferFromUserContents` ought to be pretty fast. `DataView` is mostly unoptimized, and I would expect its performance to be pretty bad.

[09:16:46.0001] <sfink>
I can think of 4 options for creating object graphs: (1) all from C++, (2) your idea of getting a chunk of data and processing it in JS, (3) going through a JSON string, and (4) going through a structured clone buffer. None of them seem all that pleasant to use, honestly.

[09:17:53.0883] <sfink>
Oh right, and also I'm guessing that you're getting very small objects because you're creating them with a generic thing that'll use the smallest object type and then filling them in? That would mean big objects are even less of a concern.

[09:20:07.0152] <wraitii>
I think you're correct on all counts yes

[09:20:50.0273] <wraitii>
When we incremental GC we actually get some freed memory, which I presume is arenas becoming completely empty (which probably happens often), but I doubt the 'uncompacted' data is a problem since we'll fill them up again, as we indeed never go idle

[09:21:31.0285] <wraitii>
wrt to 'small / big objects' I was mostly asking as a sanity-check that we wouldn't run into problems trying to allocate big arrays or something, but I had not understood that, in actuality, things like strings and arrays are mostly stored in C++ memory and not reflect in the JS heap

[09:21:45.0017] <iain>
mgaudet: The other thread I would consider pulling is looking into the specific CPUs involved and seeing if they have errata for this bug. I got as far as discovering that this particular phone apparently has an [octa-core arrangement](https://www.gsmarena.com/samsung_galaxy_s20_fe-10428.php) with two different arrangements of three different chips depending on where you bought it, and then I gave up for the day.

[09:22:37.0084] <wraitii>
ArrayBufferFromUserContents is pretty fast but I'm running into more minor GCs, which makes it maybe less efficient sometimes.

[09:22:44.0060] <wraitii>
DataView is the same but it's also slow on its own

[09:23:30.0136] <wraitii>
We're mostly using (1) right now, but to create e.g. our ECS messages, which look for example like `{ tag: 434, added:[234, 42], removed: [2324, 42] }`, that's pretty slow, as SetProperty takes a lot of time checking for things and adding slots and whatnow

[09:23:33.0348] <wraitii>
 * We're mostly using (1) right now, but to create e.g. our ECS messages, which look for example like `{ tag: 434, added:[234, 42], removed: [2324, 42] }`, that's pretty slow, as SetProperty takes a lot of time checking for things and adding slots and whatnot

[09:23:51.0448] <wraitii>
This is legitimately faster in JITted code bar the dataview/arraybufefr concerns

[09:24:06.0563] <wraitii>
I kinda doubt JSON would be faster but I haven't checked

[09:24:26.0507] <wraitii>
I don't think embedder C++ code can manually craft Structured clones, but that might be a good trick otherwise

[09:24:44.0782] <wraitii>
I also had the option of just making these proxies, but I fear that probably won't be much more efficient since we need to create arrays in some cases

[09:27:28.0042] <wraitii>
but TBH if we're looking into really optimising these, I think the fastest solution would be to re-use the last created object

[09:27:42.0918] <wraitii>
and e.g. clear() arrays and such, would also reduce GC overhead

[09:28:01.0724] <wraitii>
 * wrt to 'small / big objects' I was mostly asking as a sanity-check that we wouldn't run into problems trying to allocate big arrays or something, but I had not understood that, in actuality, things like strings and arrays are mostly stored in C++ memory and don't reflect in the JS heap

[09:29:03.0521] <mgaudet>
Yeah... cursory googling is not giving me anything nice like intel/amd errata 

[09:32:26.0799] <wraitii>
BTW is there any way from JS to interact with atomised strings for e.g. Map() objects? We have some access patterns where it would be convenient to pass the atomised string directly

[09:38:36.0317] <sfink>
`JSAtom` inherits from `JSString`, so you can use `JSAtom*` in place of `JSString*` if nothing else.

[09:39:33.0717] <sfink>
I think it'll do a dynamic flag check and then use the atom, so it should work performance-wise.

[09:40:52.0758] <wraitii>
my question was more along the lines of 'Can I, within JS, call something that takes a non-atomised function and gives me an atomised (behind the scenes) version of that string instead' ?

[09:41:03.0202] <wraitii>
and/or would it work if I wrote that C++ function 

[09:41:58.0549] <wraitii>
we have a particularly hot codepath that essentially calls Map.get(some_string_key), atomising that. In some particular case, we could pre-atomise that string. Furthermore, if the key is not found, we end up re-using the same string to set the key in the map, which as far as I can tell re-atomizes

[09:42:16.0996] <wraitii>
 * my question was more along the lines of 'Can I, within JS, call something that takes a non-atomised string and gives me an atomised (behind the scenes) version of that string instead' ?

[09:43:24.0437] <jandem>
ptomato: yeah, if you pass a custom stack to `CreateError` you probably don't need `SetPendingExceptionStack`

[09:44:14.0580] <sfink>
ah. In the past, I have recommended `asAtom = str => Object.keys({str:undefined})[0]` though that was for the purpose of saving space.

[09:45:24.0473] <sfink>
but it should work for your case. Obviously, you still wouldn't want to call it repeatedly.

[09:47:51.0328] <sfink>
especially if you fix the bug in my code above

[09:48:22.0079] <sfink>
sorry, it should be `asAtom = str => Object.keys({[str]:undefined})[0]` if you want it to work for anything but the literal `"str"`

[09:49:29.0016] <sfink>
 * ah. In the past, I have recommended `asAtom = str => Object.keys({str:undefined})[0]` (WRONG CODE, see below) though that was for the purpose of saving space.

[09:52:52.0357] <wraitii>
I see, that works but the the raw overhead from the the object construction makes it not particularly interesting here. Guess I should try a specific function, or just generally make sure that this gets called with an atomised string.

[09:52:59.0774] <wraitii>
Are 'string constants' pre-atomised in general ? 

[10:04:11.0435] <sfink>
yes (though note that I'm answering from observation, just based on what I see happening in the JS shell). The JS parser seems to create atoms for everything it sees in the source text.

[10:05:26.0276] <wraitii>
Is there an API to get a HandleValue from a Heap<JS::Value> ? Or do I have to fromMarkedLocation? 

[10:09:06.0385] <sfink>
Normally, you'd copy it to a `Rooted<JS::Value>` and then use that.

[10:10:11.0776] <sfink>
but `fromMarkedLocation` does the right thing.

[10:12:34.0569] <wraitii>
If the value is guaranteed to be already rooted (which it will be here, because I'm switching from PersistentRooted to Heap, and adding tracers), I think RootedValue just adds overhead ? 

[10:12:53.0769] <sfink>
yes

[10:14:41.0509] <iain>
> <@sfink:mozilla.org> yes (though note that I'm answering from observation, just based on what I see happening in the JS shell). The JS parser seems to create atoms for everything it sees in the source text.

I believe that we used to always atomize string literals, but we changed it to avoid atomizing long strings unnecessarily. See bug 1721413.

[10:14:42.0617] <botzilla>
https://bugzil.la/1721413 â€” RESOLVED (arai) â€” Use JSString instead of JSAtom for string literals during instantiation

[10:15:28.0774] <sfink>
you just need to be a little careful with `fromMarkedLocation`, since it's fairly easy to accidentally use it on a pointer that is not guaranteed to get marked.

[10:15:46.0749] <sfink>
but you're thinking about that already, so you should be fine

[10:17:16.0391] <iain>
Ah, this is what I was remembering: https://searchfox.org/mozilla-central/source/js/src/frontend/ParserAtom.cpp#133

[10:17:54.0865] <iain>
We always atomize latin-1 strings if they are less than 8 characters long

[10:18:50.0471] <wraitii>
Guess I'll check deeper into the code, those particular strings happen to be pretty long as well. We're definitely antipattern-ing here, but if I can get cheap speedups I'd like to do it

[10:19:24.0338] <sfink>
arai has great analysis in that bug 1721413.

[10:19:25.0397] <botzilla>
https://bugzil.la/1721413 â€” RESOLVED (arai) â€” Use JSString instead of JSAtom for string literals during instantiation

[13:38:03.0753] <sfink>
I made a minor refactoring change to the hazard analysis, just to make it a little easier to use external tooling. In my tree, that had a small side effect of going from 4 â†’ 7175 hazards. Keep it?

[13:43:42.0519] <iain>
Ah, but have you considered that if a minor refactor can increase the number of hazards by three orders of magnitude, it can also decrease the number of hazards in the same way. 0.004 hazards, here we come!

[13:48:41.0986] <sfink>
I am intrigued by your ideas and wish to subscribe to your newsletter.

[16:29:35.0923] <sfink>
the JS shell has an example of fabricating structured clone data, but it would be a pretty unusual solution. (The data format is weird but fixed; we have to be able to load ancient structured clone data from disk, so it's fully backward-compatible.)

[16:30:13.0447] <sfink>
but it sounds like these are short-lived, so in terms of maximum performance I think your idea of reusing objects would be the fastest.

[16:31:08.0585] <sfink>
you could try to reuse the Shape for the next object, but I don't tihnk that's possible via the public API. And it would still produce GC churn, as you said.

[16:33:25.0618] <sfink>
we used to have TypedObjects, which would probably fit your use case well. Those may come back someday in some other form, probably via wasm.


2023-05-31
[23:33:29.0955] <wraitii>
Could potentially be interesting for out unit data, though that would be a gain at init-time only. Thanks for your anwers regardless

[23:52:11.0841] <wraitii>
What is the difference between JS::Heap<>::get() and JS::Heap::getWithoutExpose() ? One says it 'only does a read barrier', but I'm not sure what that means in terms of our code

[23:52:53.0938] <wraitii>
and `address()`does neither of these

[06:59:15.0198] <sfink>
The read barrier is for the Gecko cycle collector. There are parts of the object graph that are marked as only reachable from the Gecko embedding but not from any other roots, and thus might be part of a garbage cycle that goes through both the GC heap as well as C++ objects and pointers. The "expose" stuff is saying "nope, this object was reachable from *something* so it must be for-real live, and therefore any cycle through it is also live."

[07:08:39.0655] <sfink>
It is not necessary if you aren't using a cycle collector. Though if you have some other kind of setup for cleaning up stuff, you might need something similar and could reuse some of the mechanisms. The CC (cycle collector) is considered to be outside of SpiderMonkey, so the embedder integration support for non-Gecko isn't really worked out.

[08:02:02.0471] <sfink>
sapling. It's... kind of awesome, actually. Once I had it set up, I really have been able to use github repos by remapping my fingers' memory from `hg` â†’ `sl` and it has all just kinda worked.

[08:02:35.0402] <sfink>
but to back up: sapling is mercurial rebased on top of the git remote repository protocol.

[08:02:39.0561] <jandem>
does it have something like evolve?

[08:02:49.0372] <sfink>
it has evolve

[08:02:51.0510] <sfink>
and topics

[08:02:59.0233] <iain>
Wait, what are topics?

[08:03:17.0353] <sfink>
better bookmarks

[08:03:47.0337] <sfink>
they are in the evolve extension's repo, but I think you have to specifically enable them

[08:04:17.0227] <mgaudet>
Yeah, I never got into topics, but will badly miss evolve if I'm ever forced away

[08:04:24.0586] <mgaudet>
which is why Sapling has been interesting

[08:04:49.0332] <sfink>
internally, they are a permanent bit of metadata associated with a commit, but they become invisible once a changeset becomes public. Which is more of an operational definition than a user-facing one.

[08:05:07.0182] <mgaudet>
(ISTR https://www.mercurial-scm.org/doc/evolution/tutorials/topic-tutorial.html explained it, but super verbosely) 

[08:05:41.0708] <iain>
Does absorb work in sapling?

[08:06:02.0147] <sfink>
part of the idea is that when you have an active topic, all relevant commands operate within that topic by default. So if the topic has a linear graph of changesets, then it's like working on a repo with a single head, which can be nice.

[08:06:10.0794] <sfink>
yes, `absorb` is in sapling

[08:06:52.0656] <sfink>
caveat: I had one time when using sapling that every command I ran waited a while and then timed out. So it's not perfect. But so far it has only happened that once.

[08:08:07.0348] <sfink>
I can't speak to performance differences because I'm only using sapling on git-native repos. I haven't experimented with checking out the git mirror of mozilla-central or anything.

[08:08:57.0069] <sfink>
it is really intended to be used with Facebook's server-side stuff for their performance goals, but so far for me it has worked fine without it.

[08:09:40.0360] <sfink>
getting Sapling installed is a bit of a PITA, and I haven't heard of anyone talking about using it outside of Meta

[08:09:59.0860] <mgaudet>
Interesting. I should give it a shot. 

Using GitHub for the techtree stuff I'm reminded of how much I find the staging area to be utterly unhelpful for 99% of my work

[08:10:05.0543] <jandem>
does it have some builtin notion of patch stacks? was reading https://sapling-scm.com/docs/introduction/getting-started/ and that seems interesting

[08:10:13.0646] <mgaudet>
so lots of "shit, I forgot to git-add"

[08:10:33.0416] <sfink>
it does. I haven't gotten around to using it, though, I'm still relying on my `hg` workflow.

[08:12:56.0398] <sfink>
yeah, git people are very attached to the staging area but it just feels like an unnecessary nuisance to me. I understand what it allows, but none of that seems any better than treating your top commit as a staging area. (Not that I would advise doing that with `git`; you'd be fighting the tooling.)

[08:19:30.0951] <Bryan Thrall [:bthrall]>
The primary benefit of the staging area is precise control over what will be committed, right?
IME, interactive commit/amend is a much better UI with the same benefit.

[08:19:43.0193] <padenot>
fwiw `git-absorb` is a thing

[08:20:59.0808] <padenot>
it's more or less the same, except instead of putting the code in the commits, it creates commits on top of the commit in which the code should go, with the string "fixup" in them, and you can `git rebase main --autosquash` and it merges them automatically

[08:21:16.0569] <padenot>
https://github.com/tummychow/git-absorb

[08:26:13.0192] <sfink>
one thing that I would very much like from my vcs that I don't know how to get: a better description of wtf I'm doing during a manual merge operation. I use diffmerge, but it's not actually about the specific tool, it's about the labels of the 3 version of the code it's showing me. The middle one is fine, it's the final result. But the meanings of the other two depend on the operation, and mercurial at least isn't feeding in enough context.

[08:27:01.0089] <mgaudet>
guilty confession: I've never developed any skills at 3-way merges. I resolve conflict markers in VSCode

[08:27:29.0793] <sfink>
for example, if I am reordering patches in my patch stack, I don't know when I'm doing a merge for the now-earlier patch vs a later one. It tries to help me by saying one is "local changes", but that's really local to part of the operation it's doing.

[08:28:02.0319] <sfink>
I tried using the vscode conflict markers. They confused me too.

[08:28:08.0459] <sfink>
perhaps I am too easily confused.

[08:28:17.0951] <jandem>
I often rebase one patch at a time (`hg next`) for that reason, but it's not ideal

[08:28:51.0587] <jandem>
 * I often rebase one patch at a time (`hg next`, `hg pick`) for that reason, but it's not ideal

[08:28:52.0454] <sfink>
yeah, I pretty much always do one `hg next` at a time, even when my stack has 35 patches in it.

[08:29:19.0274] <padenot>
I find that sometimes running `hg wip` in another terminal allows understanding where I am

[08:29:29.0912] <sfink>
hm, I don' t use `hg pick`. I should look at that.

[08:30:24.0358] <jandem>
I mostly use it to push the first commit of a stack onto current tip and then `next` for the rest. Or for reordering

[08:30:52.0550] <sfink>
that makes sense

[08:36:01.0329] <jandem>
conflict markers were a great improvement compared to MQ .rej files... 

[08:37:27.0088] <sfink>
yeah, in `mq` days I used `wiggle` to handle a lot of the automatable merging left over in the .rej files, and then convert the remainder to conflict markers.

[08:38:03.0522] <jandem>
oh right I completely forgot about that

[08:38:06.0378] <iain>
`wiggle` was a command?

[08:38:58.0412] <iain>
I suddenly feel a profound need for `wiggle` in my daily workflow

[08:38:58.0950] <iain>
Don't even really care what it does

[08:39:21.0682] <mgaudet>
https://linux.die.net/man/1/wiggle

[08:39:35.0828] <sfink>
I always felt a bit odd typing `man wiggle`

[10:16:41.0200] <wraitii>
Am I correct in thinking that 'trial inlining' is essentially monomorphizing calls to potentially polymorphic functions from monomorphic callsites, by creating a 'new variant' of said function? Would that then affect the generated code for the inlined function? In which case it might end up being a solid optimisation depending on the case. 

Does that mean 'large functions', above the max byte code length for inlining, never get monomorphised by Warp/ion ?

[10:17:36.0505] <wraitii>
furthermore, it seems 'trial inlining' is ran once only for any baseline-function (unless things get reset by an ion bailout), so would it make sense to try and time that to be as-close-to-ion-compilation-as-possible ? 

[10:17:45.0338] <iain>
wraitii: Yeah, basically

[10:18:31.0554] <wraitii>
> <@wraitii:mozilla.org> furthermore, it seems 'trial inlining' is ran once only for any baseline-function (unless things get reset by an ion bailout), so would it make sense to try and time that to be as-close-to-ion-compilation-as-possible ?

I'm asking because in a sort of a toy case here, I have function that get ion-compiled before the inner-functions get hot enough to be inlined, but in the 'long run' they'd definitely be hot enough, so we are potentially losing performance by not waiting more for trial inlining / ion compilation

[10:18:50.0206] <wraitii>
obviously everything is a bit of a moving target 

[10:18:51.0247] <iain>
 * wraitii: Yeah, basically (to the first question)

[10:21:23.0285] <wraitii>
(but the more interesting question is that maybe, even without inlining, we could trial-monomorphize)

[10:21:30.0876] <iain>
To the second question ("as-close-to-ion-compilation-as-possible"): when we do trial inlining, we effectively create a fresh set of inline caches for the callee function that is specific to that callsite. We need to spend some time populating those inline caches to make sure we have good information when Ion-compiling.

[10:23:55.0959] <iain>
Our precise inlining heuristics are a work in progress, and not especially polished. You can find them here: https://searchfox.org/mozilla-central/source/js/src/jit/TrialInlining.cpp#528

[10:24:48.0539] <wraitii>
> <@iain:mozilla.org> To the second question ("as-close-to-ion-compilation-as-possible"): when we do trial inlining, we effectively create a fresh set of inline caches for the callee function that is specific to that callsite. We need to spend some time populating those inline caches to make sure we have good information when Ion-compiling.

Ah I see, otherwise you'd bailout on the inlined function which would make it kind of pointless, right

[10:27:33.0935] <iain>
Inlining decisions are made caller-side. They don't depend on how hot the callee is overall, but they do depend on how often we've hit this specific callsite. (That's the entry count check [here](https://searchfox.org/mozilla-central/source/js/src/jit/TrialInlining.cpp#582).)

[10:30:55.0536] <iain>
You could try tweaking `JitOptions.inliningEntryThreshold` to see if that makes anything better/worse for you. The ideal value for a lot of these heuristics depends on the workload: Octane really likes inlining, but Speedometer is more ambivalent, so we cranked up the numbers as far as I could without hurting Speedometer performance. (We care about Speedometer much more than Octane.)

[10:31:59.0972] <iain>
(Lower numbers for `inliningEntryThreshold` are more aggressive)

[10:32:15.0824] <wraitii>
I think I need to play around the max byte code size / entry counts / warmup counters and see if I can see any difference in some benchmarks

[10:32:42.0748] <iain>
If you get good results let us know!

[10:32:42.0916] <wraitii>
We do have some functions that are probably good monomorphizing candidates, but almost none of them even pass the size check right now

[10:32:57.0912] <wraitii>
(btw I'm not entirely clear on the reason for that, is that to speed up compilation times?)

[10:33:10.0015] <wraitii>
(in which case we'd probably care somewhat less than regular benchmarks)

[10:34:52.0955] <iain>
Speeds up compilation times, the value of inlining large functions is lower than the value of inlining small functions, and also for technical reasons the inlined code needs to run in baseline while we are populating trial inlining ICs, so we could end up spending more time before reaching Ion 

[10:35:16.0417] <iain>
And more generally: because Speedometer gets sad if we increase the size threshold

[10:36:13.0187] <iain>
Some of our builtins (eg Array.forEach) are written in self-hosted code and we have mechanisms for cheating and inlining those even though they're technically too big

[10:36:35.0195] <iain>
But those aren't available to embedders

[10:36:37.0082] <wraitii>
I think 0 A.D. might have very different patterns to most benchmarks tbh, we're basically always running the 'same code' with no idle time, and the early game is 'free' in that we can take more time at that point to really optimise for the late-game where any microsecond matters. So I'll investigate further.

[10:37:02.0677] <iain>
Yeah, the browser cares about pageload in a way that you probably don't

[10:37:46.0065] <wraitii>
I'l try some things and report my findings if any seem interesting, thanks for the answers ðŸ˜

[10:49:05.0721] <wraitii>
Is the big difference between trial inlining and regular inlining that trial inlining requires new IC stubs where regular ilining just reuses the existing ones ?

[10:53:05.0644] <iain>
Yes. When we first implemented inlining in Warp, we were so excited by the monomorphize-using-fresh-ICs approach that we used it by default. Eventually we realized that in a bunch of cases we call something that's already monomorphic, so allocating and populating fresh ICs was just overhead. So we retroactively added regular inlining that will use data from the existing ICs in cases where the callee doesn't have any polymorphic or megamorphic ICs.

[10:54:18.0910] <iain>
(Where polymorphic = more than one stub with entry count > 0, and megamorphic = we attached six stubs and were still hitting the fallback, so we switched to a mode that generates more general ICs)

[11:00:11.0612] <wraitii>
Makes sense, thanks

[12:12:17.0768] <davidj361>
is `std::u16string` incompatible with `JS_ParseJSON`? I tried giving in `u16Str.data()` and `u16Str.c_str()` but no luck.

[12:12:34.0743] <davidj361>
 * is `std::u16string` incompatible with `JS_ParseJSON`? I tried giving in `u16Str.data()` and `u16Str.c_str()` but the function fails.

[12:12:39.0849] <davidj361>
 * is `std::u16string` incompatible with `JS_ParseJSON`? I tried giving in `u16Str.data()` and `u16Str.c_str()` but the function returns false.

[12:13:16.0146] <evilpie>
What is the exception/error?

[12:14:45.0058] <davidj361>
I can't really tell, just says assert failure at exception pending at `firefox-102.5.0/js/src/frontend/BytecodeCompiler.cpp:804`

[12:15:53.0059] <davidj361>
apparently this: `MOZ_ASSERT_IF(!cx->isHelperThreadContext(), !cx->isExceptionPending());`

[12:16:14.0218] <davidj361>
the given string should be ` { bar : 2} `

[12:16:18.0327] <davidj361>
with spaces surrounding it

[12:16:50.0265] <evilpie>
that is not valid json though

[12:17:25.0276] <davidj361>
I'm sorry...I'm an idiot

[12:24:21.0457] <davidj361>
yeah everything is all working

